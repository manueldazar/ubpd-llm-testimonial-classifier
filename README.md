#  Clasificador de Documentos Testimoniales - UBPD

**Autor:** Manuel Daza Ram铆rez  
**Versi贸n:** 2025-02  
**Demo para:** Unidad de B煤squeda de Personas dadas por Desaparecidas (UBPD)

---

##  Descripci贸n

Este proyecto implementa un **clasificador autom谩tico de documentos testimoniales** utilizando Modelos de Lenguaje (LLM) con ontolog铆a controlada. Est谩 dise帽ado para apoyar el trabajo de la UBPD en la clasificaci贸n y priorizaci贸n de testimonios relacionados con el conflicto armado colombiano.

### Contexto Institucional

La **UBPD (Unidad de B煤squeda de Personas dadas por Desaparecidas)** es una entidad del Estado colombiano creada en el marco del Acuerdo de Paz de 2016. Su misi贸n es dirigir, coordinar y contribuir a la implementaci贸n de acciones humanitarias de b煤squeda de personas dadas por desaparecidas en el contexto y en raz贸n del conflicto armado.

La UBPD recibe miles de documentos testimoniales que contienen informaci贸n cr铆tica sobre:
- **Hechos victimizantes** (desaparici贸n forzada, homicidio, desplazamiento, violencia sexual)
- **Actores armados** involucrados (guerrillas, paramilitares, fuerza p煤blica)
- **Territorios** donde ocurrieron los hechos (33 departamentos de Colombia)
- **Per铆odos temporales** del conflicto (1985-2025)

---

##  Problema que Resuelve

La clasificaci贸n manual de testimonios presenta varios desaf铆os:

| Desaf铆o | Descripci贸n |
|---------|-------------|
| **Volumen** | Miles de documentos requieren clasificaci贸n |
| **Inconsistencia** | Diferentes analistas pueden clasificar el mismo documento de formas distintas |
| **Tiempo** | La clasificaci贸n manual consume recursos humanos escasos |
| **Priorizaci贸n** | Es dif铆cil identificar r谩pidamente casos urgentes que requieren atenci贸n inmediata |

### Soluci贸n

Este sistema utiliza un **LLM (Large Language Model)** con una **ontolog铆a controlada** para:

- ?Clasificar autom谩ticamente documentos seg煤n categor铆as predefinidas
- ?Garantizar consistencia mediante vocabularios controlados
- ?Calcular scores de prioridad para enrutamiento
- ?Extraer fragmentos relevantes (highlights) para an谩lisis posterior
- ?Persistir resultados en PostgreSQL para an谩lisis y auditor铆a

---

## 锔?Arquitectura del Sistema

```
Texto crudo del documento
         ?         ???  preprocessing.py          ? Normalizaci贸n Unicode, limpieza
?  preprocess_text()         ??         ?         ???  prompts.py                ? Template few-shot + ontolog铆a
?  build_user_prompt()       ??         ?         ???  classifier.py             ? Llamada a OpenAI API (GPT-4o)
?  call_llm()                ??         ?         ???  classifier.py             ? Extracci贸n y parsing JSON
?  parse_model_response()    ??         ?         ???  classifier.py             ? Validaci贸n contra ontolog铆a
?  validate_and_fix()        ? + reglas de negocio + priority_score
?         ?         ???  db.py                     ? Persistencia en PostgreSQL
?  save_document_and_        ? (opcional)
?  classification()          ??         ?         ?Clasificaci贸n final validada + almacenada
```

---

##  Estructura del Proyecto

```
ubpd-llm-testimonial-classifier/
 src/
?   classifier.py         # Pipeline principal de clasificaci贸n
?   db.py                  # Conexi贸n PostgreSQL y persistencia
?   ontology.py            # Carga y serializaci贸n de ontolog铆a
?   preprocessing.py       # Limpieza y normalizaci贸n de texto
?   prompts.py             # System prompt y templates few-shot
?   runner.py              # CLI para ejecuci贸n desde terminal
? ontology_ubpd.yaml         # Ontolog铆a de clasificaci贸n UBPD
 requirements.txt           # Dependencias pip
 environment.yml            # Entorno Conda (Windows)
 .env                       # Variables de entorno (API keys, DB)
? run-classifier-conda.ps1   # Script PowerShell (Conda)
 run-classifier-gui.ps1     # Script PowerShell (GUI)
? notebooks/
?   UBPD_Demo_Clasificador_Testimonios_Commented.ipynb
? docs/                      # Documentaci贸n Jekyll
?   architecture.html
?   ontology.html
?   api.html
?   demo.html
? _config.yml                # Configuraci贸n Jekyll para GitHub Pages
 README.md
```

---

##  Instalaci贸n

### Prerrequisitos

- Python 3.9+ (recomendado 3.13)
- PostgreSQL 14+ (opcional, para persistencia)
- Cuenta de OpenAI con acceso a la API

### Opci贸n A: Instalaci贸n con pip

```bash
# 1. Clonar repositorio
git clone https://github.com/manueldazar/ubpd-llm-testimonial-classifier.git
cd ubpd-llm-testimonial-classifier

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Instalar dependencias
pip install -r requirements.txt
```

### Opci贸n B: Instalaci贸n con Conda (Windows)

```bash
# 1. Clonar repositorio
git clone https://github.com/manueldazar/ubpd-llm-testimonial-classifier.git
cd ubpd-llm-testimonial-classifier

# 2. Crear entorno desde environment.yml
conda env create -f environment.yml

# 3. Activar entorno
conda activate ubpd_env
```

### Configuraci贸n de Variables de Entorno

Crear archivo `.env` en el directorio ra铆z:

```env
# OpenAI API
OPENAI_API_KEY=sk-tu-api-key-aqui

# PostgreSQL (opcional)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ubpd
DB_USER=ubpd
DB_PASSWORD=ubpd
```

> 锔 **IMPORTANTE:** Nunca commitear el archivo `.env` a control de versiones.

### Configuraci贸n de Base de Datos (Opcional)

Si deseas persistir las clasificaciones:

```bash
# Crear tablas en PostgreSQL
python src/db.py create-tables
```

---

##  Uso

### Opci贸n 1: L铆nea de Comandos (CLI)

```bash
# Clasificar texto directo
python src/runner.py --text "Mi hermano desapareci贸 en 1998 en Urab谩..."

# Clasificar desde archivo
python src/runner.py --file documento.txt

# Sin guardar en base de datos
python src/runner.py --text "..." --no-db

# Con identificador externo
python src/runner.py --file doc.txt --external-id "CASO-2024-001" --source-system "SIIJEP"
```

### Opci贸n 2: Como M贸dulo Python

```python
from classifier import classify_document

testimonio = """
Yo, Mar铆a, cuento que en 1997, en el municipio de San Carlos, Antioquia, 
hombres armados que se identificaron como de la guerrilla se llevaron a mi esposo. 
Desde ese d铆a no volvimos a saber de 茅l. Despu茅s de eso comenzaron las amenazas 
y nos toc贸 salir de la vereda e irnos para Medell铆n, dejando todo atr谩s.
"""

resultado = classify_document(testimonio)
print(resultado)
```

### Opci贸n 3: Notebook Jupyter

```bash
jupyter lab notebooks/UBPD_Demo_Clasificador_Testimonios_Commented.ipynb
```

### Resultado Esperado

```json
{
  "tipo_documento": "TD1",
  "tipo_hecho": ["TH1", "TH3"],
  "territorio": ["Antioquia"],
  "periodo": "PER2",
  "actores": ["ACT2"],
  "ruteo": "RU1",
  "highlights": [
    "1997, en el municipio de San Carlos, Antioquia",
    "se llevaron a mi esposo"
  ],
  "priority_score": 0.7
}
```

---

##  Ontolog铆a UBPD

La ontolog铆a define el vocabulario controlado para la clasificaci贸n. Se carga desde `ontology_ubpd.yaml`.

### Tipo de Documento (`tipo_documento`)

| C贸digo | Descripci贸n |
|--------|-------------|
| TD0 | No testimonial |
| TD1 | Testimonio de v铆ctima directa |
| TD2 | Testimonio de familiar o persona buscadora |
| TD3 | Testimonio de exintegrante de grupo armado |
| TD4 | Testimonio de tercero testigo |

### Tipo de Hecho (`tipo_hecho`)

| C贸digo | Descripci贸n |
|--------|-------------|
| TH1 | Desaparici贸n forzada |
| TH2 | Homicidio |
| TH3 | Desplazamiento forzado |
| TH4 | Violencia sexual |
| TH5 | Reclutamiento de menores |
| TH6 | Tortura o tratos crueles |
| TH7 | Otros hechos relevantes |

### Actores (`actores`)

| C贸digo | Descripci贸n |
|--------|-------------|
| ACT0 | No aparece actor |
| ACT1 | Fuerza P煤blica o agentes estatales |
| ACT2 | Guerrillas |
| ACT3 | Paramilitares / AUC |
| ACT4 | Grupos posdesmovilizaci贸n / BACRIM |
| ACT5 | Actor no identificado |

### Per铆odo (`periodo`)

| C贸digo | Descripci贸n |
|--------|-------------|
| PER0 | No identificado |
| PER1 | 1985-1990 |
| PER2 | 1991-2000 |
| PER3 | 2001-2010 |
| PER4 | 2011-2016 |
| PER5 | 2017-2025 |

### Ruteo (`ruteo`)

| C贸digo | Descripci贸n |
|--------|-------------|
| RU0 | No aplica |
| RU1 | B煤squeda e identificaci贸n |
| RU2 | Esclarecimiento y patrones |
| RU3 | Atenci贸n psicosocial |
| RU4 | No prioritario |

### Territorio

Lista completa de los 33 departamentos de Colombia + "No identificado".

---

##  Sistema de Prioridad

El `priority_score` es un valor entre 0.0 y 1.0 calculado seg煤n:

| Condici贸n | Puntos | Justificaci贸n |
|-----------|--------|---------------|
| TH1 (Desaparici贸n forzada) | +0.4 | Mandato principal de la UBPD |
| TH4 (Violencia sexual) | +0.2 | Alto impacto, requiere atenci贸n especializada |
| RU1 (B煤squeda e identificaci贸n) | +0.3 | Caso activo de b煤squeda |
| RU3 (Atenci贸n psicosocial) | +0.1 | Requiere acompa帽amiento |

### Interpretaci贸n

```
0.0 - 0.3: Prioridad baja (documentos administrativos, no testimoniales)
0.4 - 0.6: Prioridad media (testimonios con informaci贸n parcial)
0.7 - 1.0: Prioridad alta (desapariciones activas, casos urgentes)
```

---

## 锔?Modelo de Base de Datos

El sistema persiste documentos y clasificaciones en PostgreSQL con el siguiente esquema:

```
??  doc_document      ??  (documento base)  ?     ??     ?                             ?1:N
?     ??doc_classification_ ??run (ejecuci贸n)     ??     ?     ?     ?     ?                             ?     ?     ?     ?    尖尖尖尖?    ?                       ?     ?     ?     ?                   ?    ?                       ?     ?     ?     ?                   ?? ? ? ? ? ??_labels ? ?_hecho  ? _terr? _actor?_high? ?  raw_json      ??1:1)    ? ?(1:N)   ? ?1:N)? ?1:N) ??1:N)? ?  (JSONB)       ?? ? ? ? ? ?```

### Tablas Principales

- `doc_document`: Documento original con texto y metadatos
- `doc_classification_run`: Ejecuci贸n de clasificaci贸n (modelo, timestamp)
- `doc_classification_labels`: Etiquetas simples + priority_score + raw_json
- `doc_classification_hecho`: Hechos victimizantes (multi-etiqueta)
- `doc_classification_territorio`: Territorios (multi-etiqueta)
- `doc_classification_actor`: Actores (multi-etiqueta)
- `doc_classification_highlight`: Fragmentos destacados

---

##  M贸dulos del Sistema

### `preprocessing.py`
Funciones de limpieza y normalizaci贸n de texto:
- `normalize_unicode()`: Normaliza caracteres a forma NFC
- `collapse_spaces()`: Reduce espacios m煤ltiples
- `remove_headers_and_footers()`: Elimina encabezados institucionales
- `preprocess_text()`: Pipeline completo

### `ontology.py`
Manejo de la ontolog铆a UBPD:
- `load_ontology()`: Carga YAML a diccionario Python
- `ontology_to_prompt_text()`: Serializa para incluir en prompts

### `prompts.py`
Prompts estructurados para el LLM:
- `SYSTEM_PROMPT`: Rol, ontolog铆a, reglas, formato JSON
- `USER_TEMPLATE`: Ejemplos few-shot
- `build_user_prompt()`: Inserta documento en template

### `classifier.py`
Pipeline principal:
- `call_llm()`: Llamada a OpenAI API
- `parse_model_response()`: Extracci贸n segura de JSON
- `validate_and_fix()`: Validaci贸n contra ontolog铆a
- `compute_priority()`: C谩lculo de priority_score
- `classify_document()`: Funci贸n principal

### `db.py`
Persistencia en PostgreSQL:
- `get_connection()`: Conexi贸n a BD
- `create_tables()`: Inicializaci贸n de esquema
- `save_document_and_classification()`: Guardar documento + clasificaci贸n

### `runner.py`
Interfaz de l铆nea de comandos:
- Argumentos: `--text`, `--file`, `--no-db`, `--external-id`, `--source-system`

---

## 锔 Configuraci贸n Avanzada

### Cambiar el Modelo

En `classifier.py`:

```python
MODEL_NAME = "gpt-4o"        # Por defecto
# MODEL_NAME = "gpt-4-turbo"  # Mayor capacidad
# MODEL_NAME = "gpt-3.5-turbo"  # M谩s econ贸mico
```

### Par谩metros del Modelo

```python
temperature=0.0  # Determinismo m谩ximo para clasificaci贸n consistente
```

### Extender la Ontolog铆a

Editar `ontology_ubpd.yaml` para agregar nuevos c贸digos:

```yaml
tipo_hecho:
  TH1: "Desaparici贸n forzada"
  TH8: "Nuevo tipo de hecho"  # Agregar aqu铆
```

---

## И Reglas de Negocio

El sistema implementa las siguientes reglas autom谩ticas:

1. **TD0 ?RU0**: Documentos no testimoniales no se enrutan
2. **Actor por defecto**: Si no hay actor identificado, usar `["ACT0"]`
3. **Territorio por defecto**: Si no hay ubicaci贸n, usar `["No identificado"]`
4. **Validaci贸n de c贸digos**: Solo se aceptan c贸digos de la ontolog铆a

---

##  Pr贸ximos Pasos

### Corto plazo
- [ ] Agregar retry logic y manejo de rate limits
- [ ] Implementar logging estructurado (JSON)
- [ ] Validar ontolog铆a con expertos UBPD
- [ ] Agregar m谩s ejemplos few-shot

### Mediano plazo
- [ ] Batch processing para m煤ltiples documentos
- [ ] API REST con FastAPI
- [ ] Dashboard de monitoreo
- [ ] M茅tricas de calidad (accuracy, F1)

### Largo plazo
- [ ] Fine-tuning con datos etiquetados UBPD
- [ ] Explicabilidad de clasificaciones
- [ ] B煤squeda sem谩ntica con embeddings
- [ ] Clasificaci贸n multi-documento

---

##  Documentaci贸n en L铆nea

El proyecto incluye documentaci贸n Jekyll para GitHub Pages:

- **Home**: Introducci贸n y overview
- **Architecture**: Diagrama de arquitectura
- **Ontology**: Detalle de c贸digos
- **API**: Referencia de funciones
- **Demo**: Ejemplos interactivos

Acceder en: `https://manueldazar.github.io/ubpd-llm-testimonial-classifier`

---

## 锔 Notas Importantes

- Este es un **prototipo de demostraci贸n**
- Los testimonios de ejemplo son **sint茅ticos** (no casos reales)
- En producci贸n se requiere:
  - Auditor铆a de clasificaciones
  - Revisi贸n humana de casos prioritarios
  - Monitoreo de calidad del modelo
  - Cumplimiento de normativas de datos sensibles

---

##  Contacto

**Manuel Daza Ram铆rez**  
AI Engineer - Prototipo de clasificaci贸n de documentos testimoniales

-  LinkedIn: [linkedin.com/in/manueldazaramirez](https://linkedin.com/in/manueldazaramirez)
-  Email: manuel.dazaramirez@gmail.com
-  GitHub: [github.com/manueldazar](https://github.com/manueldazar)

---

##  Licencia

Este proyecto es un prototipo de demostraci贸n desarrollado para mostrar capacidades de clasificaci贸n autom谩tica de documentos testimoniales usando LLMs.

## Crédito Intelectual y Procedencia

Este proyecto ―incluyendo su arquitectura, el dise?o de la ontología, la estrategia de *prompt engineering*, el plan de evaluación y la implementación de referencia― fue concebido, dise?ado y desarrollado por **Manuel Daza**. Todos los componentes conceptuales (formulación del problema, justificación del esquema de datos, ontología de clasificación, plantillas de *prompt*, criterios de evaluación y flujos del demostrador) se originan en este repositorio y en su historial de *commits*.

El código, la documentación y el enfoque metodológico se publican para ofrecer transparencia y fomentar una discusión responsable, y **no** constituyen autorización implícita para uso institucional, trabajo derivado con fines comerciales o despliegue operativo. Cualquier reutilización, adaptación o implementación institucional debe reconocer explícitamente al autor original y cumplir con la licencia del proyecto.

Si este proyecto se cita, referencia o utiliza como base para desarrollos posteriores, incluya la siguiente atribución:

**Manuel Daza ― Autor y Arquitecto Original**
GitHub: [https://github.com/manueldazar](https://github.com/manueldazar)
URL del proyecto: *[insertar enlace]*

Para colaboración, pilotos o acompa?amiento en la implementación, por favor contacte directamente al autor.
