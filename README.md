# LLM Testimonial Classifier

[![Python 3.9+](https://img.shields.io/badge/Python-3.9+-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-412991?logo=openai&logoColor=white)](https://openai.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14+-4169E1?logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/License-See_Terms-orange)](LICENSE)

**Clasificador autom√°tico de documentos testimoniales para organizaciones de derechos humanos**

*Automatic testimonial document classifier for human rights organizations*

---

## üìã Tabla de Contenidos

- [Descripci√≥n](#-descripci√≥n)
- [Casos de Uso](#-casos-de-uso)
- [Caracter√≠sticas](#-caracter√≠sticas)
- [Arquitectura](#-arquitectura)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Instalaci√≥n](#-instalaci√≥n)
- [Configuraci√≥n](#-configuraci√≥n)
- [Uso](#-uso)
- [Ontolog√≠a de Clasificaci√≥n](#-ontolog√≠a-de-clasificaci√≥n)
- [Base de Datos](#-base-de-datos)
- [API de M√≥dulos](#-api-de-m√≥dulos)
- [Personalizaci√≥n](#-personalizaci√≥n)
- [Pr√≥ximos Pasos](#-pr√≥ximos-pasos)
- [Cr√©dito Intelectual y Procedencia](#-cr√©dito-intelectual-y-procedencia)
- [Autor](#-autor)

---

## üìñ Descripci√≥n

Sistema de **clasificaci√≥n autom√°tica de documentos testimoniales** utilizando Modelos de Lenguaje (LLM) con ontolog√≠a controlada. Dise√±ado para organizaciones de derechos humanos, comisiones de la verdad, fiscal√≠as especializadas y entidades que procesan testimonios relacionados con conflictos armados, violaciones de derechos humanos o justicia transicional.

### El Problema

| Desaf√≠o | Descripci√≥n |
|---------|-------------|
| **Alto volumen** | Miles de testimonios pendientes de clasificaci√≥n |
| **Inconsistencia** | Variabilidad en criterios entre analistas |
| **Tiempo limitado** | Recursos humanos escasos para tareas repetitivas |
| **Priorizaci√≥n** | Dificultad para identificar casos urgentes |

### La Soluci√≥n

Un sistema que combina **GPT-4o** con una **ontolog√≠a controlada y personalizable** para:

- ‚úÖ Clasificar documentos autom√°ticamente en m√∫ltiples dimensiones
- ‚úÖ Garantizar consistencia mediante vocabularios estandarizados
- ‚úÖ Calcular scores de prioridad para enrutamiento de casos
- ‚úÖ Extraer fragmentos clave (highlights) para an√°lisis humano
- ‚úÖ Persistir resultados en PostgreSQL para auditor√≠a

---

## üéØ Casos de Uso

Este clasificador puede ser utilizado por:

| Organizaci√≥n | Aplicaci√≥n |
|--------------|------------|
| **Comisiones de la Verdad** | Procesamiento de testimonios de v√≠ctimas y testigos |
| **Fiscal√≠as Especializadas** | Clasificaci√≥n de declaraciones en casos de lesa humanidad |
| **ONGs de Derechos Humanos** | An√°lisis de denuncias y reportes de campo |
| **Unidades de B√∫squeda** | Priorizaci√≥n de casos de personas desaparecidas |
| **Tribunales de Justicia Transicional** | Categorizaci√≥n de evidencia testimonial |
| **Organizaciones Internacionales** | Procesamiento de documentaci√≥n humanitaria |

---

## ‚ú® Caracter√≠sticas

- **Clasificaci√≥n multi-etiqueta**: Tipo de documento, hechos, actores, territorio, per√≠odo
- **Ontolog√≠a YAML extensible**: F√°cil de personalizar para diferentes contextos
- **Validaci√≥n autom√°tica**: Correcci√≥n de c√≥digos inv√°lidos con valores por defecto
- **Score de prioridad**: C√°lculo autom√°tico para enrutamiento de casos
- **Persistencia PostgreSQL**: Esquema normalizado para an√°lisis y auditor√≠a
- **CLI completo**: Ejecuci√≥n desde terminal con m√∫ltiples opciones
- **Soporte Conda/pip**: Instalaci√≥n flexible para diferentes entornos

---

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        PIPELINE DE CLASIFICACI√ìN                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Documento   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇpreprocessing ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     prompts.py       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Testimonial ‚îÇ    ‚îÇ     .py      ‚îÇ    ‚îÇ  (System + Few-shot) ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                      ‚îÇ               ‚îÇ
‚îÇ                                                      ‚ñº               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ    db.py     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ    classifier.py     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Database   ‚îÇ    ‚îÇ (Persistir)  ‚îÇ    ‚îÇ  (LLM + Validaci√≥n)  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Datos

1. **Entrada**: Texto crudo del documento testimonial
2. **Preprocesamiento**: Normalizaci√≥n Unicode, limpieza de espacios
3. **Prompt Engineering**: Inyecci√≥n de ontolog√≠a + ejemplos few-shot
4. **Clasificaci√≥n LLM**: Llamada a GPT-4o con temperature=0
5. **Validaci√≥n**: Verificaci√≥n contra ontolog√≠a + reglas de negocio
6. **Enriquecimiento**: C√°lculo de priority_score
7. **Persistencia**: Almacenamiento en PostgreSQL (opcional)

---

## üìÅ Estructura del Proyecto

```
llm-testimonial-classifier/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ classifier.py        # Pipeline principal de clasificaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ db.py                 # Conexi√≥n y persistencia PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ ontology.py           # Carga de ontolog√≠a YAML
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py      # Limpieza y normalizaci√≥n de texto
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py            # System prompt y templates few-shot
‚îÇ   ‚îî‚îÄ‚îÄ runner.py             # CLI para ejecuci√≥n desde terminal
‚îÇ
‚îú‚îÄ‚îÄ ontology.yaml             # Ontolog√≠a de clasificaci√≥n (personalizable)
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias pip
‚îú‚îÄ‚îÄ environment.yml           # Entorno Conda (Windows)
‚îú‚îÄ‚îÄ .env.example              # Plantilla de variables de entorno
‚îÇ
‚îú‚îÄ‚îÄ run-classifier-conda.ps1  # Script PowerShell (Conda)
‚îú‚îÄ‚îÄ run-classifier-gui.ps1    # Script PowerShell (GUI)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ Demo_Clasificador_Testimonios.ipynb
‚îÇ
‚îú‚îÄ‚îÄ docs/                     # Documentaci√≥n Jekyll
‚îÇ   ‚îú‚îÄ‚îÄ architecture.html
‚îÇ   ‚îú‚îÄ‚îÄ ontology.html
‚îÇ   ‚îú‚îÄ‚îÄ api.html
‚îÇ   ‚îî‚îÄ‚îÄ demo.html
‚îÇ
‚îú‚îÄ‚îÄ _config.yml               # Configuraci√≥n GitHub Pages
‚îú‚îÄ‚îÄ index.md                  # Homepage del sitio
‚îî‚îÄ‚îÄ README.md                 # Este archivo
```

---

## üîß Instalaci√≥n

### Prerrequisitos

- Python 3.9+ (recomendado 3.13)
- PostgreSQL 14+ (opcional, para persistencia)
- API Key de OpenAI

### Opci√≥n A: pip (Linux/Mac/Windows)

```bash
# Clonar repositorio
git clone https://github.com/manueldazar/llm-testimonial-classifier.git
cd llm-testimonial-classifier

# Crear entorno virtual
python -m venv venv
source venv/bin/activate        # Linux/Mac
# venv\Scripts\activate         # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### Opci√≥n B: Conda (Windows)

```bash
# Clonar repositorio
git clone https://github.com/manueldazar/llm-testimonial-classifier.git
cd llm-testimonial-classifier

# Crear entorno desde environment.yml
conda env create -f environment.yml

# Activar entorno
conda activate classifier_env
```

### Dependencias Principales

| Paquete | Prop√≥sito |
|---------|-----------|
| `openai` | Cliente API OpenAI |
| `pyyaml` | Parser de ontolog√≠a YAML |
| `psycopg2-binary` | Driver PostgreSQL |
| `python-dotenv` | Variables de entorno |
| `fastapi` | API REST (opcional) |
| `uvicorn` | Servidor ASGI (opcional) |

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno

Crear archivo `.env` en el directorio ra√≠z:

```env
# === OpenAI API ===
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx

# === PostgreSQL (opcional) ===
DB_HOST=localhost
DB_PORT=5432
DB_NAME=testimonials
DB_USER=classifier
DB_PASSWORD=tu_password_seguro
```

> ‚ö†Ô∏è **Nunca commitear el archivo `.env` a Git**

### Inicializar Base de Datos (Opcional)

```bash
# Crear tablas en PostgreSQL
python src/db.py create-tables
```

---

## üöÄ Uso

### Opci√≥n 1: L√≠nea de Comandos (CLI)

```bash
# Clasificar texto directo (sin guardar en BD)
python src/runner.py --text "El testigo declara que en 1998..." --no-db

# Clasificar desde archivo
python src/runner.py --file documento.txt --no-db

# Clasificar y guardar en PostgreSQL
python src/runner.py --file documento.txt

# Con metadatos adicionales
python src/runner.py --file doc.txt --external-id "CASO-2024-001" --source-system "ARCHIVO"
```

### Opci√≥n 2: Como M√≥dulo Python

```python
from classifier import classify_document

testimonio = """
Yo, Mar√≠a, declaro que en 1997, en el municipio de San Carlos, 
hombres armados se llevaron a mi esposo. Desde ese d√≠a no volvimos 
a saber de √©l. Despu√©s comenzaron las amenazas y tuvimos que 
desplazarnos a la ciudad.
"""

resultado = classify_document(testimonio)
print(resultado)
```

### Opci√≥n 3: Notebook Jupyter

```bash
jupyter lab notebooks/Demo_Clasificador_Testimonios.ipynb
```

### Resultado Esperado

```json
{
  "tipo_documento": "TD1",
  "tipo_hecho": ["TH1", "TH3"],
  "territorio": ["Antioquia"],
  "periodo": "PER2",
  "actores": ["ACT2"],
  "ruteo": "RU1",
  "highlights": [
    "1997, en el municipio de San Carlos",
    "se llevaron a mi esposo"
  ],
  "priority_score": 0.7
}
```

---

## üìö Ontolog√≠a de Clasificaci√≥n

La ontolog√≠a define el vocabulario controlado. Se carga desde `ontology.yaml` y es completamente personalizable.

### Tipo de Documento (`tipo_documento`)

| C√≥digo | Descripci√≥n |
|--------|-------------|
| TD0 | No testimonial |
| TD1 | Testimonio de v√≠ctima directa |
| TD2 | Testimonio de familiar o persona buscadora |
| TD3 | Testimonio de exintegrante de grupo armado |
| TD4 | Testimonio de tercero testigo |

### Tipo de Hecho (`tipo_hecho`)

| C√≥digo | Descripci√≥n |
|--------|-------------|
| TH1 | Desaparici√≥n forzada |
| TH2 | Homicidio |
| TH3 | Desplazamiento forzado |
| TH4 | Violencia sexual |
| TH5 | Reclutamiento de menores |
| TH6 | Tortura o tratos crueles |
| TH7 | Otros hechos relevantes |

### Actores (`actores`)

| C√≥digo | Descripci√≥n |
|--------|-------------|
| ACT0 | No aparece actor |
| ACT1 | Fuerza P√∫blica o agentes estatales |
| ACT2 | Guerrillas |
| ACT3 | Paramilitares / AUC |
| ACT4 | Grupos posdesmovilizaci√≥n / BACRIM |
| ACT5 | Actor no identificado |

### Per√≠odo (`periodo`)

| C√≥digo | Descripci√≥n |
|--------|-------------|
| PER0 | No identificado |
| PER1 | 1985-1990 |
| PER2 | 1991-2000 |
| PER3 | 2001-2010 |
| PER4 | 2011-2016 |
| PER5 | 2017-2025 |

### Ruteo (`ruteo`)

| C√≥digo | Descripci√≥n |
|--------|-------------|
| RU0 | No aplica |
| RU1 | B√∫squeda e identificaci√≥n |
| RU2 | Esclarecimiento y patrones |
| RU3 | Atenci√≥n psicosocial |
| RU4 | No prioritario |

---

## üóÑÔ∏è Base de Datos

### Esquema Relacional

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   doc_document      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   (documento base)  ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                             ‚îÇ 1:N
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ doc_classification_ ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ run (ejecuci√≥n)     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ      ‚îÇ      ‚îÇ      ‚îÇ
                             ‚îÇ      ‚îÇ      ‚îÇ      ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                        ‚îÇ      ‚îÇ      ‚îÇ      ‚îÇ                ‚îÇ
    ‚ñº                        ‚ñº      ‚ñº      ‚ñº      ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ_labels ‚îÇ  ‚îÇ _hecho ‚îÇ  ‚îÇ _terr  ‚îÇ ‚îÇ _actor ‚îÇ ‚îÇ _high  ‚îÇ  ‚îÇ  raw_json  ‚îÇ
‚îÇ (1:1)  ‚îÇ  ‚îÇ (1:N)  ‚îÇ  ‚îÇ (1:N)  ‚îÇ ‚îÇ (1:N)  ‚îÇ ‚îÇ (1:N)  ‚îÇ  ‚îÇ  (JSONB)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tablas Principales

| Tabla | Descripci√≥n |
|-------|-------------|
| `doc_document` | Documento original con texto y metadatos |
| `doc_classification_run` | Ejecuci√≥n de clasificaci√≥n (modelo, timestamp) |
| `doc_classification_labels` | Etiquetas simples + priority_score |
| `doc_classification_hecho` | Hechos victimizantes (multi-etiqueta) |
| `doc_classification_territorio` | Territorios (multi-etiqueta) |
| `doc_classification_actor` | Actores (multi-etiqueta) |
| `doc_classification_highlight` | Fragmentos destacados |

---

## üîå API de M√≥dulos

### `preprocessing.py`

| Funci√≥n | Descripci√≥n |
|---------|-------------|
| `normalize_unicode(text)` | Normaliza caracteres a forma NFC |
| `collapse_spaces(text)` | Reduce espacios m√∫ltiples |
| `preprocess_text(text)` | Pipeline completo de limpieza |

### `ontology.py`

| Funci√≥n | Descripci√≥n |
|---------|-------------|
| `load_ontology(path)` | Carga YAML a diccionario Python |
| `ontology_to_prompt_text(ontology)` | Serializa para incluir en prompts |

### `prompts.py`

| Elemento | Descripci√≥n |
|----------|-------------|
| `SYSTEM_PROMPT` | Prompt de sistema con ontolog√≠a y reglas |
| `USER_TEMPLATE` | Template con ejemplos few-shot |
| `build_user_prompt(text)` | Construye prompt con documento |

### `classifier.py`

| Funci√≥n | Descripci√≥n |
|---------|-------------|
| `call_llm(system, user)` | Llamada a OpenAI API |
| `parse_model_response(raw)` | Extracci√≥n segura de JSON |
| `validate_and_fix(pred)` | Validaci√≥n contra ontolog√≠a |
| `compute_priority(pred)` | C√°lculo de priority_score |
| `classify_document(text)` | **Funci√≥n principal** |

### `db.py`

| Funci√≥n | Descripci√≥n |
|---------|-------------|
| `get_connection()` | Conexi√≥n a PostgreSQL |
| `create_tables()` | Inicializaci√≥n de esquema |
| `save_document_and_classification()` | Persistir documento + clasificaci√≥n |

---

## üé® Personalizaci√≥n

### Modificar la Ontolog√≠a

Editar `ontology.yaml` para adaptar a tu contexto:

```yaml
tipo_hecho:
  TH1: "Desaparici√≥n forzada"
  TH2: "Homicidio"
  TH8: "Nuevo tipo de hecho"  # Agregar nuevos c√≥digos

territorio:
  departments:
    - "Tu Regi√≥n 1"
    - "Tu Regi√≥n 2"
```

### Ajustar Pesos de Prioridad

En `classifier.py`, modificar `compute_priority()`:

```python
def compute_priority(pred: dict) -> float:
    score = 0.0
    hechos = set(pred.get("tipo_hecho", []))
    
    if "TH1" in hechos:  # Desaparici√≥n forzada
        score += 0.4    # Ajustar peso seg√∫n necesidad
    # ...
```

### Cambiar Modelo LLM

En `classifier.py`:

```python
MODEL_NAME = "gpt-4o"        # Por defecto
# MODEL_NAME = "gpt-4-turbo"  # Mayor capacidad
# MODEL_NAME = "gpt-3.5-turbo"  # M√°s econ√≥mico
```

---

## üìà Pr√≥ximos Pasos

### Corto plazo
- [ ] Retry logic y manejo de rate limits
- [ ] Logging estructurado (JSON)
- [ ] M√°s ejemplos few-shot para casos l√≠mite

### Mediano plazo
- [ ] Batch processing para m√∫ltiples documentos
- [ ] API REST con FastAPI
- [ ] Dashboard de monitoreo
- [ ] M√©tricas de calidad (accuracy, F1)

### Largo plazo
- [ ] Fine-tuning con datos etiquetados
- [ ] Explicabilidad de clasificaciones
- [ ] B√∫squeda sem√°ntica con embeddings
- [ ] Soporte multi-idioma

---

## üìú Cr√©dito Intelectual y Procedencia

### Espa√±ol

Este proyecto ‚Äîincluyendo su arquitectura, el dise√±o de la ontolog√≠a, la estrategia de prompt engineering, el plan de evaluaci√≥n y la implementaci√≥n de referencia‚Äî fue concebido, dise√±ado y desarrollado por **Manuel Daza**. Todos los componentes conceptuales (formulaci√≥n del problema, justificaci√≥n del esquema de datos, ontolog√≠a de clasificaci√≥n, plantillas de prompt, criterios de evaluaci√≥n y flujos del demostrador) se originan en este repositorio y en su historial de commits.

El c√≥digo, la documentaci√≥n y el enfoque metodol√≥gico se publican para ofrecer transparencia y fomentar una discusi√≥n responsable, y **no constituyen autorizaci√≥n impl√≠cita** para uso institucional, trabajo derivado con fines comerciales o despliegue operativo. Cualquier reutilizaci√≥n, adaptaci√≥n o implementaci√≥n institucional debe reconocer expl√≠citamente al autor original y cumplir con la licencia del proyecto.

**Si este proyecto se cita, referencia o utiliza como base para desarrollos posteriores, incluya la siguiente atribuci√≥n:**

> **Manuel Daza** ‚Äî Autor y Arquitecto Original  
> GitHub: [https://github.com/manueldazar](https://github.com/manueldazar)  
> URL del proyecto: [https://github.com/manueldazar/llm-testimonial-classifier](https://github.com/manueldazar/llm-testimonial-classifier)

Para colaboraci√≥n, pilotos o acompa√±amiento en la implementaci√≥n, por favor contacte directamente al autor.

---

### English ‚Äî Intellectual Credit and Provenance

This project ‚Äîincluding its architecture, ontology design, prompt engineering strategy, evaluation plan, and reference implementation‚Äî was conceived, designed, and developed by **Manuel Daza**. All conceptual components (problem formulation, data schema rationale, classification ontology, prompt templates, evaluation criteria, and demonstrator workflows) originate in this repository and its commit history.

The code, documentation, and methodological approach are published to provide transparency and encourage responsible discussion, and **do not constitute implicit authorization** for institutional use, commercial derivative work, or operational deployment. Any reuse, adaptation, or institutional implementation must explicitly acknowledge the original author and comply with the project license.

**If this project is cited, referenced, or used as a basis for further development, please include the following attribution:**

> **Manuel Daza** ‚Äî Original Author and Architect  
> GitHub: [https://github.com/manueldazar](https://github.com/manueldazar)  
> Project URL: [https://github.com/manueldazar/llm-testimonial-classifier](https://github.com/manueldazar/llm-testimonial-classifier)

For collaboration, pilots, or implementation support, please contact the author directly.

---

## üë®‚Äçüíª Autor

**Manuel Daza Ram√≠rez**  
AI Engineer

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?logo=linkedin&logoColor=white)](https://linkedin.com/in/manueldazaramirez)
[![GitHub](https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white)](https://github.com/manueldazar)
[![Email](https://img.shields.io/badge/Email-D14836?logo=gmail&logoColor=white)](mailto:manuel.dazaramirez@gmail.com)

---

## ‚ö†Ô∏è Aviso Legal

Este es un **prototipo de demostraci√≥n**. Los testimonios de ejemplo son **sint√©ticos** y no representan casos reales. El despliegue en producci√≥n requiere:

- Revisi√≥n humana de clasificaciones de alta prioridad
- Auditor√≠a y logging para trazabilidad
- Cumplimiento de normativas de protecci√≥n de datos sensibles
- Validaci√≥n con expertos del dominio espec√≠fico
