{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79c1622",
   "metadata": {},
   "source": [
    "# Demo – Clasificador de documentos testimoniales\n",
    "\n",
    "**Autor:** Manuel Daza Ramirez  \n",
    "**Proyecto:** Demo – UBPD: Clasificador de documentos testimoniales\n",
    "\n",
    "---\n",
    "\n",
    "## Contexto institucional\n",
    "\n",
    "La **UBPD (Unidad de Búsqueda de Personas dadas por Desaparecidas)** es una entidad del Estado colombiano creada en el marco del Acuerdo de Paz de 2016. Su misión es dirigir, coordinar y contribuir a la implementación de acciones humanitarias de búsqueda de personas dadas por desaparecidas en el contexto y en razón del conflicto armado.\n",
    "\n",
    "La UBPD recibe miles de documentos testimoniales de familiares de víctimas, organizaciones sociales y otras fuentes. Estos documentos contienen información crítica sobre:\n",
    "- **Hechos victimizantes** (desaparición forzada, masacres, desplazamiento)\n",
    "- **Actores armados** involucrados (guerrillas, paramilitares, fuerza pública)\n",
    "- **Territorios** donde ocurrieron los hechos\n",
    "- **Períodos temporales** del conflicto\n",
    "\n",
    "---\n",
    "\n",
    "## Problema que resuelve este prototipo\n",
    "\n",
    "La clasificación manual de testimonios presenta varios desafíos:\n",
    "\n",
    "1. **Volumen**: Miles de documentos requieren clasificación.\n",
    "2. **Inconsistencia**: Diferentes analistas pueden clasificar el mismo documento de formas distintas.\n",
    "3. **Tiempo**: La clasificación manual consume recursos humanos escasos.\n",
    "4. **Priorización**: Es difícil identificar rápidamente casos urgentes que requieren atención inmediata.\n",
    "\n",
    "Este prototipo utiliza un **LLM (Large Language Model)** con una **ontología controlada** para:\n",
    "- Clasificar automáticamente documentos según categorías predefinidas\n",
    "- Garantizar consistencia mediante vocabularios controlados\n",
    "- Calcular scores de prioridad para enrutamiento\n",
    "- Extraer fragmentos relevantes (highlights) para análisis posterior\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo técnico\n",
    "\n",
    "- Cargar la ontología UBPD desde un archivo YAML.\n",
    "- Construir prompts estructurados (system + user) que fuerzan al LLM a devolver un JSON con etiquetas controladas.\n",
    "- Implementar funciones de preprocesamiento, llamada al modelo, parsing de JSON y validación de etiquetas.\n",
    "- Exponer una función principal `classify_document(text)` y un ejemplo de uso con un testimonio de prueba.\n",
    "\n",
    "## Estructura del notebook\n",
    "\n",
    "1. **Configuración del entorno** - Cliente OpenAI y variables globales\n",
    "2. **Preprocesamiento de texto** - Limpieza y normalización de documentos\n",
    "3. **Carga de ontología** - YAML → estructura Python\n",
    "4. **Serialización para prompts** - Ontología → texto legible para el LLM\n",
    "5. **Definición de prompts** - System prompt con reglas + User template con ejemplos\n",
    "6. **Cliente LLM** - Función de llamada al modelo\n",
    "7. **Extracción de JSON** - Parsing seguro de respuestas\n",
    "8. **Validación y normalización** - Corrección de etiquetas inválidas\n",
    "9. **Cálculo de prioridad** - Score para enrutamiento de casos\n",
    "10. **Función principal** - Pipeline completo de clasificación\n",
    "11. **Ejemplo de uso** - Demostración con testimonio sintético\n",
    "\n",
    "> **Nota**: Este notebook es un demo. En producción se integraría con bases de datos, mecanismos de auditoría, logging estructurado y monitoreo de calidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuración inicial del entorno\n",
    "\n",
    "Esta sección establece las dependencias y configuración necesarias para el funcionamiento del clasificador.\n",
    "\n",
    "### Decisiones de diseño:\n",
    "- **`python-dotenv`**: Permite cargar la API key desde un archivo `.env`, evitando hardcodear credenciales en el código.\n",
    "- **`dataclass`**: Aunque no se usa extensivamente aquí, facilita la creación de estructuras de datos tipadas en Python.\n",
    "- **Cliente OpenAI**: Se usa el SDK oficial de OpenAI. En producción, podría sustituirse por Azure OpenAI, Anthropic Claude, o modelos locales.\n",
    "\n",
    "### Configuración del modelo:\n",
    "- **`temperature=0.0`** (en la llamada): Respuestas determinísticas para clasificación consistente.\n",
    "- El modelo se especifica globalmente para facilitar cambios (ej. migrar de GPT-4 a GPT-4o)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e451b-fbd5-4166-8cd5-4ae54ccd17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 1: CONFIGURACIÓN INICIAL DEL ENTORNO\n",
    "# ==============================================================================\n",
    "# Autor: Manuel Daza Ramirez\n",
    "#\n",
    "# Propósito:\n",
    "#   Establecer las importaciones necesarias, cargar credenciales de forma segura\n",
    "#   y configurar el cliente del modelo de lenguaje.\n",
    "#\n",
    "# Dependencias requeridas (instalar con pip):\n",
    "#   - python-dotenv: Carga variables de entorno desde archivo .env\n",
    "#   - openai: SDK oficial para interactuar con la API de OpenAI\n",
    "#   - pyyaml: Parser de archivos YAML para la ontología\n",
    "# ==============================================================================\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carga variables de entorno desde el archivo .env en el directorio raíz\n",
    "# El archivo .env debe contener: OPENAI_API_KEY=sk-...\n",
    "# IMPORTANTE: Nunca commitear el archivo .env a control de versiones\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Importaciones estándar para manipulación de datos\n",
    "import json          # Parsing de respuestas JSON del modelo\n",
    "import textwrap      # Utilidad para formateo de texto (no usada activamente aquí)\n",
    "from dataclasses import dataclass  # Para estructuras de datos tipadas\n",
    "from typing import List, Dict, Any  # Type hints para mejor documentación\n",
    "\n",
    "# Cliente OpenAI - inicializa automáticamente con OPENAI_API_KEY del entorno\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURACIÓN GLOBAL DEL MODELO\n",
    "# ==============================================================================\n",
    "# Modelo a utilizar para la clasificación.\n",
    "# Opciones comunes:\n",
    "#   - \"gpt-4o\": Modelo multimodal, buen balance costo/rendimiento\n",
    "#   - \"gpt-4-turbo\": Alta capacidad, mayor costo\n",
    "#   - \"gpt-3.5-turbo\": Más económico, menor precisión en tareas complejas\n",
    "#\n",
    "# NOTA: Cambiar este valor para probar diferentes modelos sin modificar código\n",
    "# ==============================================================================\n",
    "MODEL_NAME = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Preprocesamiento de texto\n",
    "\n",
    "Los documentos testimoniales pueden venir de diversas fuentes (escaneos OCR, transcripciones, formularios digitales) y frecuentemente contienen:\n",
    "- **Caracteres Unicode malformados**: Tildes descompuestas, espacios especiales\n",
    "- **Espacios múltiples**: Resultado de copiar/pegar desde PDFs\n",
    "- **Headers/footers institucionales**: Que no aportan al contenido testimonial\n",
    "\n",
    "### Funciones implementadas:\n",
    "\n",
    "| Función | Propósito |\n",
    "|---------|----------|\n",
    "| `normalize_unicode()` | Convierte caracteres a forma canónica NFC |\n",
    "| `collapse_spaces()` | Reduce espacios múltiples a uno solo |\n",
    "| `remove_headers_and_footers()` | Placeholder para patrones específicos UBPD |\n",
    "| `preprocess_text()` | Pipeline completo de limpieza |\n",
    "\n",
    "### Por qué es importante:\n",
    "- El LLM procesa tokens; texto sucio puede desperdiciar tokens en ruido.\n",
    "- La normalización mejora la consistencia de las clasificaciones.\n",
    "- Prepara el texto para futuros procesamientos (embeddings, búsqueda, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81b1fb-f579-436a-b73f-3ae11c070d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 2: PREPROCESAMIENTO DE TEXTO\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Limpiar y normalizar el texto de los documentos testimoniales antes de\n",
    "#   enviarlo al modelo. Esto mejora la calidad de la clasificación y reduce\n",
    "#   el consumo de tokens en texto irrelevante.\n",
    "#\n",
    "# El preprocesamiento es ligero intencionalmente:\n",
    "#   - NO elimina puntuación (importante para el contexto)\n",
    "#   - NO convierte a minúsculas (nombres propios son significativos)\n",
    "#   - NO hace stemming/lemmatization (el LLM maneja esto internamente)\n",
    "# ==============================================================================\n",
    "\n",
    "import re           # Expresiones regulares para manipulación de texto\n",
    "import unicodedata  # Normalización de caracteres Unicode\n",
    "\n",
    "\n",
    "def normalize_unicode(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza el texto a forma canónica Unicode NFC.\n",
    "    \n",
    "    ¿Por qué NFC?\n",
    "    -------------\n",
    "    En Unicode, algunos caracteres pueden representarse de múltiples formas:\n",
    "    - \"á\" puede ser un solo carácter (U+00E1) \n",
    "    - O la combinación de \"a\" (U+0061) + acento (U+0301)\n",
    "    \n",
    "    NFC (Canonical Decomposition, followed by Canonical Composition) asegura\n",
    "    que caracteres equivalentes se representen de forma idéntica, evitando\n",
    "    problemas de comparación y búsqueda.\n",
    "    \n",
    "    Args:\n",
    "        text: Texto de entrada posiblemente con Unicode no normalizado\n",
    "        \n",
    "    Returns:\n",
    "        Texto con caracteres Unicode en forma NFC\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> normalize_unicode(\"café\")  # Con tilde descompuesta\n",
    "        'café'  # Con tilde compuesta\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "\n",
    "def collapse_spaces(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Reduce múltiples espacios en blanco consecutivos a un solo espacio.\n",
    "    \n",
    "    Caso de uso:\n",
    "    ------------\n",
    "    Documentos escaneados con OCR o copiados de PDFs frecuentemente tienen\n",
    "    espacios múltiples, tabulaciones y saltos de línea irregulares que\n",
    "    no aportan significado semántico.\n",
    "    \n",
    "    El patrón \\s+ captura:\n",
    "    - Espacios simples y múltiples\n",
    "    - Tabulaciones (\\t)\n",
    "    - Saltos de línea (\\n, \\r)\n",
    "    - Otros caracteres de espacio Unicode\n",
    "    \n",
    "    Args:\n",
    "        text: Texto con posibles espacios múltiples\n",
    "        \n",
    "    Returns:\n",
    "        Texto con espacios normalizados y sin espacios al inicio/final\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> collapse_spaces(\"Hola    mundo  \")\n",
    "        'Hola mundo'\n",
    "    \"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def remove_headers_and_footers(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Elimina encabezados y pies de página institucionales del documento.\n",
    "    \n",
    "    Estado actual: PLACEHOLDER\n",
    "    --------------------------\n",
    "    Esta función está preparada para incorporar patrones específicos de la UBPD\n",
    "    una vez se identifiquen los formatos comunes de documentos.\n",
    "    \n",
    "    Patrones típicos a eliminar (ejemplos hipotéticos):\n",
    "    - \"UNIDAD DE BÚSQUEDA DE PERSONAS DADAS POR DESAPARECIDAS\"\n",
    "    - \"Página X de Y\"\n",
    "    - Números de radicado\n",
    "    - Firmas digitales y timestamps\n",
    "    \n",
    "    TODO: Implementar patrones reales basados en documentos UBPD\n",
    "    \n",
    "    Args:\n",
    "        text: Texto del documento completo\n",
    "        \n",
    "    Returns:\n",
    "        Texto sin elementos institucionales no relevantes para clasificación\n",
    "    \"\"\"\n",
    "    # Ejemplo de implementación futura:\n",
    "    # patterns = [\n",
    "    #     r\"^UBPD.*?\\n\",  # Header institucional\n",
    "    #     r\"Página \\d+ de \\d+\",  # Numeración de páginas\n",
    "    # ]\n",
    "    # for pattern in patterns:\n",
    "    #     text = re.sub(pattern, \"\", text, flags=re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Pipeline completo de preprocesamiento para documentos testimoniales.\n",
    "    \n",
    "    Orden de operaciones:\n",
    "    --------------------\n",
    "    1. normalize_unicode: Garantiza consistencia de caracteres\n",
    "    2. remove_headers_and_footers: Elimina ruido institucional\n",
    "    3. collapse_spaces: Limpia espacios redundantes\n",
    "    \n",
    "    El orden importa:\n",
    "    - La normalización Unicode debe ser primera para que los patrones regex\n",
    "      en pasos posteriores funcionen correctamente.\n",
    "    - collapse_spaces va al final para limpiar espacios que pudieron quedar\n",
    "      tras remover headers/footers.\n",
    "    \n",
    "    Args:\n",
    "        text: Texto crudo del documento testimonial\n",
    "        \n",
    "    Returns:\n",
    "        Texto limpio y normalizado, listo para clasificación\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> raw = \"  Yo,  María,   cuento que en 1997...  \"\n",
    "        >>> preprocess_text(raw)\n",
    "        'Yo, María, cuento que en 1997...'\n",
    "    \"\"\"\n",
    "    text = normalize_unicode(text)\n",
    "    text = remove_headers_and_footers(text)\n",
    "    text = collapse_spaces(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ontology-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Carga de la ontología UBPD\n",
    "\n",
    "La **ontología** es el corazón del sistema de clasificación. Define el vocabulario controlado que garantiza:\n",
    "\n",
    "1. **Consistencia**: Todos los documentos se clasifican con las mismas categorías.\n",
    "2. **Interoperabilidad**: Los códigos pueden mapearse a sistemas externos (bases de datos, dashboards).\n",
    "3. **Auditabilidad**: Las clasificaciones son trazables a categorías bien definidas.\n",
    "\n",
    "### Estructura de la ontología YAML:\n",
    "\n",
    "```yaml\n",
    "tipo_documento:        # Naturaleza del documento\n",
    "  TD0: \"No testimonial\"\n",
    "  TD1: \"Testimonio de víctima directa\"\n",
    "  TD2: \"Testimonio de familiar\"\n",
    "  ...\n",
    "\n",
    "tipo_hecho:            # Hechos victimizantes descritos\n",
    "  TH0: \"No aplica\"\n",
    "  TH1: \"Desaparición forzada\"\n",
    "  TH2: \"Homicidio\"\n",
    "  TH3: \"Desplazamiento forzado\"\n",
    "  TH4: \"Masacre\"\n",
    "  ...\n",
    "\n",
    "actores:               # Presuntos responsables\n",
    "  ACT0: \"No identificado\"\n",
    "  ACT1: \"Paramilitares\"\n",
    "  ACT2: \"Guerrilla\"\n",
    "  ACT3: \"Fuerza pública\"\n",
    "  ...\n",
    "\n",
    "periodo:               # Época del conflicto\n",
    "  PER0: \"No identificado\"\n",
    "  PER1: \"Antes de 1985\"\n",
    "  PER2: \"1985-2000\"\n",
    "  ...\n",
    "\n",
    "ruteo:                 # Área interna para seguimiento\n",
    "  RU0: \"Sin asignación\"\n",
    "  RU1: \"Equipo de búsqueda prioritario\"\n",
    "  RU3: \"Archivo general\"\n",
    "  ...\n",
    "```\n",
    "\n",
    "### ¿Por qué YAML?\n",
    "- Legible para humanos (analistas pueden revisarlo sin programar)\n",
    "- Fácil de versionar en Git\n",
    "- Extensible sin cambiar código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398fa375-95aa-4bd5-9261-9edc7c11a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 3: CARGA DE LA ONTOLOGÍA UBPD\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Cargar el vocabulario controlado desde un archivo YAML externo.\n",
    "#   La ontología define todas las categorías válidas para clasificación.\n",
    "#\n",
    "# Ventajas de externalizar la ontología:\n",
    "#   - Modificable sin cambiar código (ej. agregar nuevos tipos de hecho)\n",
    "#   - Versionable independientemente del código\n",
    "#   - Reutilizable en otros sistemas (validadores, dashboards, reportes)\n",
    "#\n",
    "# Estructura esperada del YAML:\n",
    "#   tipo_documento: {código: descripción}\n",
    "#   tipo_hecho: {código: descripción}\n",
    "#   territorio: [lista] o {código: descripción}\n",
    "#   periodo: {código: descripción}\n",
    "#   actores: {código: descripción}\n",
    "#   ruteo: {código: descripción}\n",
    "# ==============================================================================\n",
    "\n",
    "import yaml  # Parser de archivos YAML\n",
    "\n",
    "\n",
    "def load_ontology(path=\"../ontology_ubpd.yaml\"):\n",
    "    \"\"\"\n",
    "    Carga la ontología UBPD desde un archivo YAML.\n",
    "    \n",
    "    El archivo YAML define el vocabulario controlado para clasificación:\n",
    "    - Códigos cortos (TD1, TH2, ACT3) para procesamiento\n",
    "    - Descripciones legibles para interpretación humana\n",
    "    \n",
    "    Args:\n",
    "        path: Ruta al archivo YAML de ontología.\n",
    "              Por defecto busca en el directorio padre (../)\n",
    "              \n",
    "    Returns:\n",
    "        dict: Diccionario con la estructura completa de la ontología\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: Si el archivo YAML no existe\n",
    "        yaml.YAMLError: Si el archivo tiene sintaxis YAML inválida\n",
    "        \n",
    "    Ejemplo de uso:\n",
    "        >>> ontology = load_ontology(\"ontology_ubpd.yaml\")\n",
    "        >>> print(ontology[\"tipo_hecho\"][\"TH1\"])\n",
    "        'Desaparición forzada'\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)  # safe_load previene ejecución de código arbitrario\n",
    "\n",
    "\n",
    "# Carga global de la ontología al iniciar el notebook\n",
    "# Esta variable se usa en múltiples funciones posteriores\n",
    "ONTOLOGY = load_ontology()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serialize-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Serialización de ontología para el prompt\n",
    "\n",
    "El LLM necesita conocer las categorías válidas para clasificar correctamente. Esta función convierte la ontología de Python a un formato de texto legible que se inyecta en el **system prompt**.\n",
    "\n",
    "### Estrategia de prompt engineering:\n",
    "\n",
    "Al incluir la lista completa de códigos válidos en el prompt, logramos:\n",
    "\n",
    "1. **Restricción de vocabulario**: El modelo solo puede usar códigos que existen.\n",
    "2. **Autodocumentación**: Las descripciones ayudan al modelo a elegir correctamente.\n",
    "3. **Flexibilidad**: Cambios en la ontología se reflejan automáticamente.\n",
    "\n",
    "### Formato de salida:\n",
    "\n",
    "```\n",
    "1. tipo_documento:\n",
    "   - \"TD0\": \"No testimonial\"\n",
    "   - \"TD1\": \"Testimonio de víctima directa\"\n",
    "   ...\n",
    "\n",
    "2. tipo_hecho:\n",
    "   - \"TH0\": \"No aplica\"\n",
    "   - \"TH1\": \"Desaparición forzada\"\n",
    "   ...\n",
    "```\n",
    "\n",
    "Este formato es:\n",
    "- Estructurado (numeración, indentación)\n",
    "- No ambiguo (códigos entre comillas)\n",
    "- Completo (todas las opciones visibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b39e56-e44c-40a9-939b-85ef7d6590e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 4: SERIALIZACIÓN DE ONTOLOGÍA PARA EL PROMPT\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Convertir la estructura de datos de la ontología (dict Python) a un\n",
    "#   formato de texto legible que pueda incluirse en el prompt del modelo.\n",
    "#\n",
    "# Esta es una técnica clave de prompt engineering:\n",
    "#   - El modelo ve TODAS las opciones válidas\n",
    "#   - Cada código tiene su descripción para guiar la elección\n",
    "#   - El formato estructurado facilita el parsing mental del modelo\n",
    "# ==============================================================================\n",
    "\n",
    "def ontology_to_prompt_text(ontology: dict) -> str:\n",
    "    \"\"\"\n",
    "    Convierte la ontología cargada desde YAML a un bloque de texto\n",
    "    estructurado para incluir en el system prompt del modelo.\n",
    "    \n",
    "    Formato de salida:\n",
    "    -----------------\n",
    "    Cada categoría se presenta con:\n",
    "    - Número de sección (1, 2, 3...)\n",
    "    - Nombre de la categoría\n",
    "    - Lista de códigos con sus descripciones\n",
    "    \n",
    "    Decisiones de formato:\n",
    "    - Comillas dobles alrededor de códigos: Evita ambigüedad\n",
    "    - Indentación con espacios: Legibilidad visual\n",
    "    - Líneas en blanco entre secciones: Separación clara\n",
    "    \n",
    "    Args:\n",
    "        ontology: Diccionario con la estructura de la ontología\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto formateado listo para insertar en el prompt\n",
    "        \n",
    "    Nota sobre territorio:\n",
    "        El campo territorio puede ser una lista simple [\"Antioquia\", \"Chocó\"]\n",
    "        o un diccionario {código: descripción}. La función maneja ambos casos.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Tipo de documento: Clasifica la naturaleza del documento\n",
    "    # TD0=No testimonial, TD1=Testimonio víctima, TD2=Testimonio familiar, etc.\n",
    "    # ---------------------------------------------------------------------------\n",
    "    lines.append(\"1. tipo_documento:\")\n",
    "    for code, label in ontology[\"tipo_documento\"].items():\n",
    "        lines.append(f'   - \"{code}\": \"{label}\"')\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Tipo de hecho: Hechos victimizantes mencionados en el documento\n",
    "    # Puede haber múltiples hechos en un mismo testimonio\n",
    "    # ---------------------------------------------------------------------------\n",
    "    lines.append(\"\\n2. tipo_hecho:\")\n",
    "    for code, label in ontology[\"tipo_hecho\"].items():\n",
    "        lines.append(f'   - \"{code}\": \"{label}\"')\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Territorio: Ubicación geográfica de los hechos\n",
    "    # Formato flexible: puede ser lista o diccionario según el YAML\n",
    "    # ---------------------------------------------------------------------------\n",
    "    if \"territorio\" in ontology:\n",
    "        lines.append(\"\\n3. territorio:\")\n",
    "        if isinstance(ontology[\"territorio\"], list):\n",
    "            # Caso: lista simple de departamentos\n",
    "            for item in ontology[\"territorio\"]:\n",
    "                lines.append(f'   - \"{item}\"')\n",
    "        else:\n",
    "            # Caso: diccionario código → descripción\n",
    "            for k, v in ontology[\"territorio\"].items():\n",
    "                lines.append(f'   - \"{k}\": \"{v}\"')\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Periodo: Época del conflicto en que ocurrieron los hechos\n",
    "    # Importante para contextualización histórica\n",
    "    # ---------------------------------------------------------------------------\n",
    "    lines.append(\"\\n4. periodo:\")\n",
    "    for code, label in ontology[\"periodo\"].items():\n",
    "        lines.append(f'   - \"{code}\": \"{label}\"')\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Actores: Presuntos responsables de los hechos\n",
    "    # Categoría sensible que requiere precisión\n",
    "    # ---------------------------------------------------------------------------\n",
    "    lines.append(\"\\n5. actores:\")\n",
    "    for code, label in ontology[\"actores\"].items():\n",
    "        lines.append(f'   - \"{code}\": \"{label}\"')\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Ruteo: Área interna de la UBPD para seguimiento del caso\n",
    "    # Determina el flujo de trabajo posterior\n",
    "    # ---------------------------------------------------------------------------\n",
    "    lines.append(\"\\n6. ruteo:\")\n",
    "    for code, label in ontology[\"ruteo\"].items():\n",
    "        lines.append(f'   - \"{code}\": \"{label}\"')\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Pre-calcular el texto de ontología para reutilizar en el prompt\n",
    "# Esto evita regenerarlo en cada llamada de clasificación\n",
    "ONTOLOGY_PROMPT = ontology_to_prompt_text(ONTOLOGY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "system-prompt-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Definición del System Prompt\n",
    "\n",
    "El **system prompt** es la instrucción principal que define el comportamiento del modelo. Es el componente más crítico del sistema.\n",
    "\n",
    "### Principios de diseño aplicados:\n",
    "\n",
    "| Principio | Implementación |\n",
    "|-----------|---------------|\n",
    "| **Rol claro** | \"Eres un clasificador\" - establece la identidad |\n",
    "| **Restricciones explícitas** | Lista cerrada de códigos válidos |\n",
    "| **Formato obligatorio** | Template JSON exacto a seguir |\n",
    "| **Reglas de negocio** | \"Si TD0 entonces RU0\" |\n",
    "| **Auto-verificación** | Instrucciones internas para que el modelo valide |\n",
    "| **Salida limpia** | \"SOLO el JSON, sin texto adicional\" |\n",
    "\n",
    "### Anatomía del prompt:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┐\n",
    "│  1. Definición de rol                   │\n",
    "├─────────────────────────────────────────┤\n",
    "│  2. Ontología completa (códigos válidos)│\n",
    "├─────────────────────────────────────────┤\n",
    "│  3. Reglas de negocio                   │\n",
    "├─────────────────────────────────────────┤\n",
    "│  4. Formato JSON obligatorio            │\n",
    "├─────────────────────────────────────────┤\n",
    "│  5. Instrucciones de auto-verificación  │\n",
    "└─────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Reglas de negocio implementadas:\n",
    "\n",
    "1. **TD0 → RU0**: Documentos no testimoniales no se enrutan a equipos de búsqueda.\n",
    "2. **Actor por defecto**: Si no hay actor identificado, usar `ACT0`.\n",
    "3. **Territorio por defecto**: Si no hay ubicación, usar `[\"No identificado\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6df41a-ced1-444c-b039-fb4e8a2dc0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 5: DEFINICIÓN DEL SYSTEM PROMPT\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Definir las instrucciones principales que guían el comportamiento del modelo.\n",
    "#   Este prompt establece:\n",
    "#     - El rol del modelo (clasificador)\n",
    "#     - Los vocabularios válidos (ontología)\n",
    "#     - Las reglas de negocio (ej. TD0 → RU0)\n",
    "#     - El formato de salida (JSON estricto)\n",
    "#     - Instrucciones de auto-verificación\n",
    "#\n",
    "# Técnicas de prompt engineering utilizadas:\n",
    "#   1. Role prompting: \"Eres un clasificador\"\n",
    "#   2. Constraint prompting: Listas cerradas de códigos\n",
    "#   3. Format specification: Template JSON exacto\n",
    "#   4. Chain-of-thought implícito: \"INSTRUCCIONES INTERNAS\"\n",
    "#   5. Self-verification: \"VERIFICA tú mismo\"\n",
    "# ==============================================================================\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "Eres un clasificador. Tu única tarea es devolver un JSON válido con etiquetas que usen EXCLUSIVAMENTE los códigos de esta ontología:\n",
    "\n",
    "CÓDIGOS VÁLIDOS (listas cerradas):\n",
    "{ONTOLOGY_PROMPT}\n",
    "\n",
    "Reglas clave:\n",
    "- tipo_documento ∈ lista tipo_documento.\n",
    "- tipo_hecho ⊆ lista tipo_hecho (puede ser lista vacía).\n",
    "- periodo ∈ lista periodo.\n",
    "- actores ∈ lista actores (si no aparece ningún actor, usa [\"ACT0\"]).\n",
    "- ruteo ∈ lista ruteo.\n",
    "- territorio es una lista de nombres de departamentos de Colombia o [\"No identificado\"].\n",
    "- highlights es una lista de frases textuales del documento (puede estar vacía).\n",
    "- Si tipo_documento = \"TD0\" entonces ruteo = \"RU0\".\n",
    "\n",
    "Formato JSON OBLIGATORIO (ni más ni menos campos):\n",
    "\n",
    "{{\n",
    "  \"tipo_documento\": \"TDx\",\n",
    "  \"tipo_hecho\": [\"THx\", \"...\"],\n",
    "  \"territorio\": [\"Nombre departamento o 'No identificado'\", \"...\"],\n",
    "  \"periodo\": \"PERx\",\n",
    "  \"actores\": [\"ACTx\", \"...\"],\n",
    "  \"ruteo\": \"RUx\",\n",
    "  \"highlights\": [\"frase 1\", \"frase 2\", ...]\n",
    "}}\n",
    "\n",
    "INSTRUCCIONES INTERNAS (no las muestres):\n",
    "1) Lee el documento y decide las etiquetas adecuadas.\n",
    "2) Construye mentalmente el JSON.\n",
    "3) VERIFICA tú mismo:\n",
    "   - ¿Todos los campos existen y solo esos?\n",
    "   - ¿Todos los códigos pertenecen a las listas válidas?\n",
    "   - ¿Se cumple la regla: si TD0 → RU0?\n",
    "   - ¿Territorio es una lista y no está vacía (si no hay info, [\"No identificado\"])?\n",
    "   - ¿highlights es una lista (posiblemente vacía)?\n",
    "4) Si encuentras algún error, corrígelo antes de responder.\n",
    "5) Responde SOLO el JSON final, sin texto adicional.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Nota sobre el uso de f-string con dobles llaves {{}}:\n",
    "# Las dobles llaves se escapan a llaves simples en el string final.\n",
    "# Esto es necesario porque {ONTOLOGY_PROMPT} es una variable f-string,\n",
    "# pero las llaves del template JSON deben permanecer literales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "user-prompt-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Template del User Prompt con Few-Shot Examples\n",
    "\n",
    "El **user prompt** contiene el documento a clasificar junto con **ejemplos demostrativos** (few-shot learning).\n",
    "\n",
    "### ¿Por qué few-shot prompting?\n",
    "\n",
    "Los ejemplos ayudan al modelo a:\n",
    "1. **Entender el formato esperado**: JSON concreto, no abstracto.\n",
    "2. **Calibrar el nivel de detalle**: Qué tan específicos deben ser los highlights.\n",
    "3. **Manejar casos límite**: El Ejemplo 2 muestra qué hacer con documentos no testimoniales.\n",
    "\n",
    "### Estructura del template:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┐\n",
    "│  Ejemplo 1: Testimonio de desaparición  │\n",
    "│  - Entrada (texto)                      │\n",
    "│  - Salida esperada (JSON)               │\n",
    "├─────────────────────────────────────────┤\n",
    "│  Ejemplo 2: Documento no testimonial    │\n",
    "│  - Entrada (texto)                      │\n",
    "│  - Salida esperada (JSON)               │\n",
    "├─────────────────────────────────────────┤\n",
    "│  Documento a clasificar                 │\n",
    "│  {{DOCUMENTO}}                          │\n",
    "├─────────────────────────────────────────┤\n",
    "│  Recordatorio de reglas                 │\n",
    "└─────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Selección de ejemplos:\n",
    "\n",
    "| Ejemplo | Propósito | Características |\n",
    "|---------|-----------|----------------|\n",
    "| **Ejemplo 1** | Caso típico | Desaparición forzada, territorio específico, actor identificado |\n",
    "| **Ejemplo 2** | Caso negativo | Documento administrativo, muestra TD0 y valores vacíos |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53ed44-d6a8-4eb1-a0fe-aa036a78c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 6: TEMPLATE DEL USER PROMPT CON EJEMPLOS (FEW-SHOT)\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Definir el template que contiene los ejemplos demostrativos y el\n",
    "#   marcador de posición para el documento a clasificar.\n",
    "#\n",
    "# Few-shot learning:\n",
    "#   Al mostrar ejemplos concretos de entrada→salida, el modelo aprende:\n",
    "#   - El formato exacto del JSON esperado\n",
    "#   - Cómo mapear contenido textual a códigos de ontología\n",
    "#   - Cómo manejar casos donde información no está disponible\n",
    "#\n",
    "# Selección de ejemplos:\n",
    "#   Ejemplo 1: Testimonio típico con información completa\n",
    "#     - Tipo: Testimonio de víctima (TD1)\n",
    "#     - Hechos: Desaparición forzada (TH1), desplazamiento (TH3)\n",
    "#     - Ubicación específica: San Carlos, Antioquia\n",
    "#     - Actor: Guerrilla (ACT2)\n",
    "#     - Ruteo: Equipo prioritario (RU1)\n",
    "#\n",
    "#   Ejemplo 2: Documento NO testimonial (contraejemplo)\n",
    "#     - Tipo: No testimonial (TD0)\n",
    "#     - Demuestra uso de valores por defecto\n",
    "#     - Ruteo obligatorio RU0 por regla de negocio\n",
    "# ==============================================================================\n",
    "\n",
    "USER_TEMPLATE = \"\"\"\n",
    "Ejemplo 1 (entrada):\n",
    "\"Yo, María, cuento que en 1997, en el municipio de San Carlos, Antioquia, hombres armados de la guerrilla se llevaron a mi esposo. Nos tocó salir para Medellín.\"\n",
    "\n",
    "Ejemplo 1 (salida):\n",
    "{\n",
    "  \"tipo_documento\": \"TD1\",\n",
    "  \"tipo_hecho\": [\"TH1\",\"TH3\"],\n",
    "  \"territorio\": [\"Antioquia\"],\n",
    "  \"periodo\": \"PER2\",\n",
    "  \"actores\": [\"ACT2\"],\n",
    "  \"ruteo\": \"RU1\",\n",
    "  \"highlights\": [\n",
    "    \"1997, en el municipio de San Carlos, Antioquia\",\n",
    "    \"se llevaron a mi esposo\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Ejemplo 2 (entrada):\n",
    "\"Oficio No. 123 de 2020. Remito informe técnico sobre la migración de datos.\"\n",
    "\n",
    "Ejemplo 2 (salida):\n",
    "{\n",
    "  \"tipo_documento\": \"TD0\",\n",
    "  \"tipo_hecho\": [],\n",
    "  \"territorio\": [\"No identificado\"],\n",
    "  \"periodo\": \"PER5\",\n",
    "  \"actores\": [\"ACT0\"],\n",
    "  \"ruteo\": \"RU0\",\n",
    "  \"highlights\": []\n",
    "}\n",
    "\n",
    "Ahora clasifica este documento siguiendo estrictamente el formato de los ejemplos y las reglas del sistema:\n",
    "\n",
    "DOCUMENTO:\n",
    "{{DOCUMENTO}}\n",
    "\n",
    "Recuerda:\n",
    "- Usa únicamente los códigos válidos.\n",
    "- Verifica internamente que el JSON cumple todas las reglas.\n",
    "- Responde SOLO el JSON, sin comentarios adicionales.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def build_user_prompt(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Construye el prompt de usuario insertando el documento a clasificar.\n",
    "    \n",
    "    El marcador {{DOCUMENTO}} se reemplaza con el texto limpio del documento.\n",
    "    Se usa doble llave para evitar conflictos con f-strings de Python.\n",
    "    \n",
    "    Args:\n",
    "        text: Texto del documento ya preprocesado\n",
    "        \n",
    "    Returns:\n",
    "        str: Prompt completo con ejemplos y documento a clasificar\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> prompt = build_user_prompt(\"Mi hermano desapareció en 2003...\")\n",
    "        >>> \"Mi hermano desapareció\" in prompt\n",
    "        True\n",
    "    \"\"\"\n",
    "    return USER_TEMPLATE.replace(\"{{DOCUMENTO}}\", text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-call-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Cliente LLM y función de llamada\n",
    "\n",
    "Esta función encapsula la comunicación con el modelo de lenguaje.\n",
    "\n",
    "### Parámetros clave:\n",
    "\n",
    "| Parámetro | Valor | Justificación |\n",
    "|-----------|-------|---------------|\n",
    "| `model` | `MODEL_NAME` | Configurable globalmente |\n",
    "| `temperature` | `0.0` | **Determinismo**: Misma entrada → misma salida |\n",
    "| `messages` | system + user | Separación de instrucciones y datos |\n",
    "\n",
    "### ¿Por qué temperature=0.0?\n",
    "\n",
    "Para tareas de **clasificación** donde necesitamos:\n",
    "- **Reproducibilidad**: El mismo documento debe clasificarse igual siempre.\n",
    "- **Auditabilidad**: Resultados deben ser explicables y consistentes.\n",
    "- **Confianza**: Reducir variabilidad en decisiones importantes.\n",
    "\n",
    "### Estructura de mensajes:\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # Instrucciones permanentes\n",
    "    {\"role\": \"user\", \"content\": user_prompt}       # Documento + ejemplos\n",
    "]\n",
    "```\n",
    "\n",
    "El rol `system` tiene mayor peso que `user` en la mayoría de los modelos, lo que refuerza las restricciones de la ontología."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504ddfd-b8e3-4fcb-afda-3a06b8424361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 7: CLIENTE LLM Y FUNCIÓN DE LLAMADA\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Encapsular la comunicación con el modelo de lenguaje en una función\n",
    "#   reutilizable que maneja la estructura de mensajes y parámetros.\n",
    "#\n",
    "# Diseño:\n",
    "#   - Recibe prompts como parámetros (no hardcodeados)\n",
    "#   - Usa temperature=0.0 para clasificación determinística\n",
    "#   - Retorna texto crudo para procesamiento posterior\n",
    "#\n",
    "# Extensibilidad:\n",
    "#   Esta función puede modificarse para:\n",
    "#   - Usar otros proveedores (Azure OpenAI, Anthropic, local)\n",
    "#   - Agregar retry logic para errores de red\n",
    "#   - Implementar rate limiting\n",
    "#   - Agregar logging de llamadas\n",
    "# ==============================================================================\n",
    "\n",
    "def call_llm(system_prompt: str, user_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Realiza una llamada al modelo de lenguaje y retorna la respuesta.\n",
    "    \n",
    "    Estructura de la llamada:\n",
    "    ------------------------\n",
    "    - system_prompt: Instrucciones de alto nivel (rol, reglas, formato)\n",
    "    - user_prompt: Documento a clasificar con ejemplos few-shot\n",
    "    \n",
    "    Configuración:\n",
    "    - model: Especificado por MODEL_NAME global\n",
    "    - temperature: 0.0 para máximo determinismo\n",
    "      (el modelo elegirá siempre el token más probable)\n",
    "    \n",
    "    Args:\n",
    "        system_prompt: Instrucciones del sistema con ontología y reglas\n",
    "        user_prompt: Documento a clasificar envuelto en template con ejemplos\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto crudo de la respuesta del modelo (idealmente JSON puro)\n",
    "        \n",
    "    Raises:\n",
    "        openai.APIError: Si hay problemas de comunicación con la API\n",
    "        openai.RateLimitError: Si se excede el límite de solicitudes\n",
    "        \n",
    "    Nota sobre el código muerto:\n",
    "        El `raise NotImplementedError` después del return es código\n",
    "        inalcanzable, probablemente residuo de desarrollo. En producción\n",
    "        debería eliminarse.\n",
    "    \"\"\"\n",
    "    # Construir la solicitud al modelo\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            # El mensaje \"system\" establece el contexto persistente\n",
    "            # El modelo lo trata como instrucciones de mayor autoridad\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            \n",
    "            # El mensaje \"user\" contiene el documento específico a clasificar\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        # temperature=0.0: Elimina aleatoriedad en la selección de tokens\n",
    "        # Esto hace que la clasificación sea reproducible\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    # Extraer el contenido de texto de la primera opción de respuesta\n",
    "    # En configuraciones típicas solo hay una opción (n=1 por defecto)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    # NOTA: Este código es inalcanzable y debería eliminarse en producción\n",
    "    raise NotImplementedError(\"Implementa aquí la llamada real al LLM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "json-extract-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Extracción segura de JSON\n",
    "\n",
    "Aunque el prompt pide \"SOLO el JSON\", los modelos a veces agregan texto adicional. Estas funciones manejan esa variabilidad.\n",
    "\n",
    "### Casos que maneja `extract_json_block`:\n",
    "\n",
    "```\n",
    "Caso 1 (ideal): Solo JSON\n",
    "{\"tipo_documento\": \"TD1\", ...}\n",
    "\n",
    "Caso 2: JSON con texto antes\n",
    "Aquí está la clasificación:\n",
    "{\"tipo_documento\": \"TD1\", ...}\n",
    "\n",
    "Caso 3: JSON con texto después\n",
    "{\"tipo_documento\": \"TD1\", ...}\n",
    "Espero que esto sea útil.\n",
    "\n",
    "Caso 4: JSON envuelto en markdown\n",
    "```json\n",
    "{\"tipo_documento\": \"TD1\", ...}\n",
    "```\n",
    "```\n",
    "\n",
    "### Estrategia:\n",
    "1. Buscar la primera `{` (inicio del JSON)\n",
    "2. Buscar la última `}` (fin del JSON)\n",
    "3. Extraer la subcadena entre ambas posiciones\n",
    "\n",
    "**Limitación**: Si hay múltiples objetos JSON, solo extrae el más externo. Para nuestro caso de uso (un solo JSON de clasificación) esto es suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677e1ea-9c3a-4a9c-bae2-0d289f85a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 8: EXTRACCIÓN SEGURA DE JSON\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Extraer de forma robusta el JSON de clasificación de la respuesta del modelo,\n",
    "#   manejando casos donde el modelo incluye texto adicional.\n",
    "#\n",
    "# Problema:\n",
    "#   Aunque el prompt pide \"SOLO el JSON\", los modelos a veces agregan:\n",
    "#   - Texto introductorio: \"Aquí está la clasificación:\"\n",
    "#   - Bloques de código markdown: ```json ... ```\n",
    "#   - Explicaciones finales: \"Nota: el periodo es...\"\n",
    "#\n",
    "# Solución:\n",
    "#   Buscar los delimitadores del JSON ({ y }) y extraer solo ese bloque.\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_json_block(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrae el primer bloque JSON del texto de respuesta del modelo.\n",
    "    \n",
    "    Algoritmo:\n",
    "    ---------\n",
    "    1. Busca la primera aparición de '{' (inicio del objeto JSON)\n",
    "    2. Busca la última aparición de '}' (fin del objeto JSON)\n",
    "    3. Retorna la subcadena entre ambas posiciones (inclusive)\n",
    "    \n",
    "    Este enfoque es simple pero efectivo para el caso de uso:\n",
    "    - Esperamos UN SOLO objeto JSON por respuesta\n",
    "    - El JSON de clasificación siempre es un objeto (no array)\n",
    "    - No hay JSON anidado que pudiera confundir los delimitadores\n",
    "    \n",
    "    Args:\n",
    "        text: Respuesta cruda del modelo, posiblemente con texto adicional\n",
    "        \n",
    "    Returns:\n",
    "        str: Bloque JSON extraído como string\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: Si no se encuentra un JSON válido (sin { o sin })\n",
    "        \n",
    "    Ejemplos:\n",
    "        >>> extract_json_block('Resultado: {\"a\": 1}')\n",
    "        '{\"a\": 1}'\n",
    "        >>> extract_json_block('```json\\n{\"a\": 1}\\n```')\n",
    "        '{\"a\": 1}'\n",
    "    \"\"\"\n",
    "    # Encontrar posición del primer carácter '{'\n",
    "    start = text.find(\"{\")\n",
    "    \n",
    "    # Encontrar posición del último carácter '}'\n",
    "    # Usamos rfind (reverse find) para encontrar desde el final\n",
    "    end = text.rfind(\"}\")\n",
    "    \n",
    "    # Validar que ambos delimitadores existan y estén en orden correcto\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        raise ValueError(\"No se encontró un JSON válido en la respuesta del modelo.\")\n",
    "    \n",
    "    # Extraer subcadena incluyendo ambos delimitadores (+1 para incluir '}')\n",
    "    return text[start:end+1]\n",
    "\n",
    "\n",
    "def parse_model_response(raw_response: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parsea la respuesta del modelo a un diccionario Python.\n",
    "    \n",
    "    Pipeline:\n",
    "    1. extract_json_block: Aisla el JSON del texto circundante\n",
    "    2. json.loads: Convierte string JSON a dict Python\n",
    "    \n",
    "    Args:\n",
    "        raw_response: Respuesta cruda del modelo\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con la clasificación parseada\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: Si no hay JSON en la respuesta\n",
    "        json.JSONDecodeError: Si el JSON está malformado\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> parse_model_response('{\"tipo_documento\": \"TD1\"}')\n",
    "        {'tipo_documento': 'TD1'}\n",
    "    \"\"\"\n",
    "    json_str = extract_json_block(raw_response)\n",
    "    return json.loads(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Helpers de validación y normalización\n",
    "\n",
    "Aunque el LLM está instruido para usar solo códigos válidos, puede cometer errores. Estas funciones proporcionan una **red de seguridad** que garantiza que la salida final siempre cumpla con la ontología.\n",
    "\n",
    "### Filosofía: \"Trust but verify\"\n",
    "\n",
    "- **Confiar**: El prompt está diseñado para producir salidas correctas.\n",
    "- **Verificar**: La validación post-hoc corrige errores silenciosamente.\n",
    "\n",
    "### Funciones de corrección:\n",
    "\n",
    "| Función | Entrada | Comportamiento |\n",
    "|---------|---------|----------------|\n",
    "| `fix_single_label` | String | Devuelve default si código inválido |\n",
    "| `fix_multi_labels` | Lista | Filtra códigos inválidos |\n",
    "| `fix_territorio` | Lista | Normaliza y asegura lista no vacía |\n",
    "\n",
    "### Valores por defecto:\n",
    "\n",
    "| Campo | Default | Significado |\n",
    "|-------|---------|-------------|\n",
    "| `tipo_documento` | TD0 | No testimonial |\n",
    "| `periodo` | PER0 | No identificado |\n",
    "| `ruteo` | RU0 | Sin asignación |\n",
    "| `territorio` | [\"No identificado\"] | Ubicación desconocida |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df798457-9e78-4c3f-a2e2-2d98d0d7f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 9: HELPERS DE VALIDACIÓN Y NORMALIZACIÓN\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Funciones auxiliares para corregir y normalizar etiquetas de clasificación.\n",
    "#   Actúan como red de seguridad cuando el modelo produce códigos inválidos.\n",
    "#\n",
    "# Principio de diseño:\n",
    "#   - Nunca fallar silenciosamente\n",
    "#   - Siempre producir una salida válida (usando defaults cuando sea necesario)\n",
    "#   - Preservar la mayor cantidad de información correcta posible\n",
    "#\n",
    "# Estas funciones NO modifican el input original, retornan valores corregidos.\n",
    "# ==============================================================================\n",
    "\n",
    "def fix_single_label(value: str, valid_codes, default: str) -> str:\n",
    "    \"\"\"\n",
    "    Valida y corrige una etiqueta de valor único.\n",
    "    \n",
    "    Usado para campos que aceptan UN SOLO valor:\n",
    "    - tipo_documento\n",
    "    - periodo\n",
    "    - ruteo\n",
    "    \n",
    "    Lógica:\n",
    "    - Si el valor está en la lista de códigos válidos → lo retorna tal cual\n",
    "    - Si el valor es inválido → retorna el default\n",
    "    \n",
    "    Args:\n",
    "        value: Código retornado por el modelo\n",
    "        valid_codes: Iterable de códigos válidos (ej. ONTOLOGY[\"periodo\"].keys())\n",
    "        default: Valor a usar si el código es inválido\n",
    "        \n",
    "    Returns:\n",
    "        str: Código válido (original o default)\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> fix_single_label(\"TD1\", [\"TD0\", \"TD1\", \"TD2\"], \"TD0\")\n",
    "        'TD1'  # Válido, retorna tal cual\n",
    "        >>> fix_single_label(\"TDX\", [\"TD0\", \"TD1\", \"TD2\"], \"TD0\")\n",
    "        'TD0'  # Inválido, retorna default\n",
    "    \"\"\"\n",
    "    if value in valid_codes:\n",
    "        return value\n",
    "    return default\n",
    "\n",
    "\n",
    "def fix_multi_labels(values, valid_codes) -> List[str]:\n",
    "    \"\"\"\n",
    "    Valida y filtra una lista de etiquetas múltiples.\n",
    "    \n",
    "    Usado para campos que aceptan MÚLTIPLES valores:\n",
    "    - tipo_hecho (puede haber varios hechos victimizantes)\n",
    "    - actores (puede haber varios actores involucrados)\n",
    "    \n",
    "    Lógica:\n",
    "    - Si la entrada no es lista → retorna lista vacía\n",
    "    - Filtra solo los valores que están en valid_codes\n",
    "    - Códigos inválidos se descartan silenciosamente\n",
    "    \n",
    "    Args:\n",
    "        values: Lista de códigos retornada por el modelo (o None/otro tipo)\n",
    "        valid_codes: Iterable de códigos válidos\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Lista filtrada con solo códigos válidos\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> fix_multi_labels([\"TH1\", \"TH2\", \"INVALID\"], [\"TH1\", \"TH2\", \"TH3\"])\n",
    "        ['TH1', 'TH2']  # INVALID se descarta\n",
    "        >>> fix_multi_labels(\"TH1\", [\"TH1\", \"TH2\"])  # String en vez de lista\n",
    "        []  # Retorna lista vacía\n",
    "    \"\"\"\n",
    "    if not isinstance(values, list):\n",
    "        return []\n",
    "    return [v for v in values if v in valid_codes]\n",
    "\n",
    "\n",
    "def fix_territorio(values: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Normaliza y valida la lista de territorios.\n",
    "    \n",
    "    El territorio es un caso especial:\n",
    "    - No usa códigos predefinidos (son nombres de departamentos)\n",
    "    - Debe ser siempre una lista no vacía\n",
    "    - Si está vacío, usar [\"No identificado\"]\n",
    "    \n",
    "    Normalizaciones:\n",
    "    - Elimina espacios al inicio/final de cada valor\n",
    "    - Elimina duplicados (usando set)\n",
    "    \n",
    "    Args:\n",
    "        values: Lista de nombres de departamentos/territorios\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Lista normalizada y deduplicada, o [\"No identificado\"]\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> fix_territorio([\" Antioquia \", \"Chocó\", \"Antioquia\"])\n",
    "        ['Antioquia', 'Chocó']  # Normalizado y deduplicado\n",
    "        >>> fix_territorio([])  # Lista vacía\n",
    "        ['No identificado']  # Default\n",
    "    \"\"\"\n",
    "    # Validar que sea lista no vacía\n",
    "    if not isinstance(values, list) or len(values) == 0:\n",
    "        return [\"No identificado\"]\n",
    "    \n",
    "    # Normalizar: strip + deduplicar\n",
    "    # El set elimina duplicados, luego convertimos a lista\n",
    "    return list({v.strip() for v in values})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "priority-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Cálculo de prioridad para enrutamiento\n",
    "\n",
    "El **priority_score** es un valor numérico [0.0, 1.0] que ayuda a priorizar casos para atención.\n",
    "\n",
    "### Lógica de puntuación:\n",
    "\n",
    "| Condición | Puntos | Justificación |\n",
    "|-----------|--------|---------------|\n",
    "| TH1 (Desaparición forzada) | +0.4 | Mandato principal de la UBPD |\n",
    "| TH4 (Masacre) | +0.2 | Alto impacto, múltiples víctimas |\n",
    "| RU1 (Equipo prioritario) | +0.3 | Ya identificado como urgente |\n",
    "| RU3 (Archivo general) | +0.1 | Relevancia menor pero presente |\n",
    "\n",
    "### Interpretación del score:\n",
    "\n",
    "```\n",
    "0.0 - 0.3: Prioridad baja (documentos administrativos, casos cerrados)\n",
    "0.4 - 0.6: Prioridad media (testimonios con información parcial)\n",
    "0.7 - 1.0: Prioridad alta (desapariciones activas, nuevas pistas)\n",
    "```\n",
    "\n",
    "### Notas de diseño:\n",
    "\n",
    "- Los pesos son **configurables** y deberían ajustarse con expertos del dominio.\n",
    "- El `min(score, 1.0)` garantiza que el score nunca exceda 1.0.\n",
    "- En producción, este cálculo podría evolucionar a un modelo ML más sofisticado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc3f63-42bc-48bc-ae24-5a0b9ba14f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 10: CÁLCULO DE PRIORIDAD PARA ENRUTAMIENTO\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Calcular un score de prioridad [0.0, 1.0] basado en las etiquetas\n",
    "#   de clasificación. Este score ayuda a ordenar casos para atención.\n",
    "#\n",
    "# Contexto de negocio:\n",
    "#   La UBPD tiene recursos limitados y debe priorizar casos donde:\n",
    "#   - Hay desaparición forzada (su mandato principal)\n",
    "#   - Hay múltiples víctimas (masacres)\n",
    "#   - El documento ya fue enrutado a equipos especializados\n",
    "#\n",
    "# Los pesos actuales son un punto de partida; deberían calibrarse\n",
    "# con datos históricos y expertos del dominio.\n",
    "# ==============================================================================\n",
    "\n",
    "def compute_priority(pred: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Calcula un score de prioridad basado en la clasificación.\n",
    "    \n",
    "    Sistema de puntos:\n",
    "    -----------------\n",
    "    El score es la suma de puntos por condiciones cumplidas:\n",
    "    \n",
    "    +0.4 puntos si tipo_hecho incluye TH1 (Desaparición forzada)\n",
    "         Razón: Es el mandato principal de la UBPD\n",
    "    \n",
    "    +0.2 puntos si tipo_hecho incluye TH4 (Masacre)\n",
    "         Razón: Alto impacto, afecta múltiples familias\n",
    "    \n",
    "    +0.3 puntos si ruteo es RU1 (Equipo de búsqueda prioritario)\n",
    "         Razón: Ya identificado como caso urgente\n",
    "    \n",
    "    +0.1 puntos si ruteo es RU3 (Archivo general)\n",
    "         Razón: Tiene relevancia pero menor urgencia\n",
    "    \n",
    "    Ejemplos de scores:\n",
    "    - Desaparición + Equipo prioritario: 0.4 + 0.3 = 0.7\n",
    "    - Masacre + Desaparición + Prioritario: 0.4 + 0.2 + 0.3 = 0.9\n",
    "    - Documento no testimonial: 0.0\n",
    "    \n",
    "    Args:\n",
    "        pred: Diccionario con la clasificación del documento\n",
    "        \n",
    "    Returns:\n",
    "        float: Score de prioridad entre 0.0 y 1.0\n",
    "        \n",
    "    Nota: El score se limita a 1.0 máximo aunque la suma pudiera excederlo.\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    # Extraer campos relevantes con defaults seguros\n",
    "    hechos = set(pred.get(\"tipo_hecho\", []))  # Convertir a set para búsqueda O(1)\n",
    "    ruteo = pred.get(\"ruteo\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Puntos por tipo de hecho\n",
    "    # -------------------------------------------------------------------------\n",
    "    if \"TH1\" in hechos:  # Desaparición forzada\n",
    "        score += 0.4\n",
    "        # Esta es la prioridad más alta porque es el mandato central de la UBPD:\n",
    "        # buscar personas desaparecidas en el contexto del conflicto armado.\n",
    "    \n",
    "    if \"TH4\" in hechos:  # Masacre\n",
    "        score += 0.2\n",
    "        # Las masacres implican múltiples víctimas y frecuentemente\n",
    "        # están relacionadas con desapariciones en fosas comunes.\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Puntos por ruteo asignado\n",
    "    # -------------------------------------------------------------------------\n",
    "    if ruteo == \"RU1\":  # Equipo de búsqueda prioritario\n",
    "        score += 0.3\n",
    "        # El clasificador o una regla previa ya identificó este caso\n",
    "        # como merecedor de atención especializada.\n",
    "    \n",
    "    if ruteo == \"RU3\":  # Archivo general\n",
    "        score += 0.1\n",
    "        # Documentos que van al archivo tienen menor urgencia\n",
    "        # pero siguen siendo relevantes para investigación histórica.\n",
    "\n",
    "    # Limitar el score máximo a 1.0\n",
    "    # Esto normaliza el score independientemente de cuántas condiciones se cumplan\n",
    "    return min(score, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "full-validation-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Validación completa de la predicción\n",
    "\n",
    "Esta función integra todas las validaciones individuales y aplica **reglas de negocio** adicionales.\n",
    "\n",
    "### Pipeline de validación:\n",
    "\n",
    "```\n",
    "Predicción cruda del modelo\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│ 1. Validar tipo_documento           │\n",
    "│ 2. Validar tipo_hecho               │\n",
    "│ 3. Validar periodo                  │\n",
    "│ 4. Validar actores                  │\n",
    "│ 5. Validar ruteo                    │\n",
    "│ 6. Normalizar territorio            │\n",
    "│ 7. Aplicar regla TD0 → RU0          │\n",
    "│ 8. Garantizar highlights es lista   │\n",
    "│ 9. Calcular priority_score          │\n",
    "└─────────────────────────────────────┘\n",
    "         │\n",
    "         ▼\n",
    "Predicción validada y enriquecida\n",
    "```\n",
    "\n",
    "### Regla de negocio: TD0 → RU0\n",
    "\n",
    "Si el documento es **no testimonial** (TD0), automáticamente se asigna al ruteo **sin asignación** (RU0). Esto evita que documentos administrativos lleguen a equipos de búsqueda.\n",
    "\n",
    "### Enriquecimiento:\n",
    "\n",
    "La función añade `priority_score` que no viene del modelo pero es calculado localmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc435249-c972-406f-bb82-33df45517fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 11: VALIDACIÓN COMPLETA DE LA PREDICCIÓN\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Aplicar todas las validaciones y reglas de negocio a la predicción\n",
    "#   del modelo antes de retornar el resultado final.\n",
    "#\n",
    "# Esta función es el \"firewall\" final que garantiza:\n",
    "#   - Todos los códigos son válidos según la ontología\n",
    "#   - Las reglas de negocio se cumplen (ej. TD0 → RU0)\n",
    "#   - Los campos tienen los tipos correctos (listas, strings)\n",
    "#   - Se añade el campo calculado priority_score\n",
    "#\n",
    "# IMPORTANTE: Esta función MODIFICA el diccionario in-place.\n",
    "# En producción, considerar hacer una copia para inmutabilidad.\n",
    "# ==============================================================================\n",
    "\n",
    "def validate_and_fix(pred: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Valida y corrige la predicción del modelo aplicando la ontología\n",
    "    y las reglas de negocio.\n",
    "    \n",
    "    Proceso:\n",
    "    -------\n",
    "    1. Validar cada campo contra su lista de códigos válidos\n",
    "    2. Aplicar valores por defecto donde sea necesario\n",
    "    3. Ejecutar reglas de negocio (ej. TD0 → RU0)\n",
    "    4. Garantizar tipos de datos correctos\n",
    "    5. Calcular y añadir priority_score\n",
    "    \n",
    "    Args:\n",
    "        pred: Diccionario con la predicción cruda del modelo\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Predicción validada, corregida y enriquecida\n",
    "        \n",
    "    Side effects:\n",
    "        Modifica el diccionario pred in-place (además de retornarlo)\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> raw = {\"tipo_documento\": \"INVALID\", \"tipo_hecho\": [\"TH1\", \"BAD\"]}\n",
    "        >>> fixed = validate_and_fix(raw)\n",
    "        >>> fixed[\"tipo_documento\"]\n",
    "        'TD0'  # Corregido a default\n",
    "        >>> fixed[\"tipo_hecho\"]\n",
    "        ['TH1']  # 'BAD' fue filtrado\n",
    "    \"\"\"\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Validación de campos de valor único\n",
    "    # Cada campo se valida contra su lista de códigos en la ontología\n",
    "    # Si el código es inválido, se usa el default especificado\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    pred[\"tipo_documento\"] = fix_single_label(\n",
    "        pred.get(\"tipo_documento\"),           # Valor del modelo\n",
    "        ONTOLOGY[\"tipo_documento\"].keys(),    # Códigos válidos: TD0, TD1, TD2...\n",
    "        default=\"TD0\"                         # Default: No testimonial\n",
    "    )\n",
    "\n",
    "    pred[\"periodo\"] = fix_single_label(\n",
    "        pred.get(\"periodo\"),\n",
    "        ONTOLOGY[\"periodo\"].keys(),           # Códigos válidos: PER0, PER1, PER2...\n",
    "        default=\"PER0\"                        # Default: No identificado\n",
    "    )\n",
    "\n",
    "    pred[\"ruteo\"] = fix_single_label(\n",
    "        pred.get(\"ruteo\"),\n",
    "        ONTOLOGY[\"ruteo\"].keys(),             # Códigos válidos: RU0, RU1, RU2...\n",
    "        default=\"RU0\"                         # Default: Sin asignación\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Validación de campos multi-valor\n",
    "    # Filtra códigos inválidos, preservando los válidos\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    pred[\"tipo_hecho\"] = fix_multi_labels(\n",
    "        pred.get(\"tipo_hecho\", []),           # Lista de hechos del modelo\n",
    "        ONTOLOGY[\"tipo_hecho\"].keys()         # Códigos válidos: TH0, TH1, TH2...\n",
    "    )\n",
    "\n",
    "    pred[\"actores\"] = fix_multi_labels(\n",
    "        pred.get(\"actores\", []),              # Lista de actores del modelo\n",
    "        ONTOLOGY[\"actores\"].keys()            # Códigos válidos: ACT0, ACT1, ACT2...\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Normalización de territorio\n",
    "    # No usa códigos fijos, pero debe ser lista no vacía\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    pred[\"territorio\"] = fix_territorio(pred.get(\"territorio\", []))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # REGLA DE NEGOCIO: TD0 → RU0\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Si el documento no es testimonial (TD0), no debe enrutarse a ningún\n",
    "    # equipo de búsqueda. Se fuerza el ruteo a RU0 (Sin asignación).\n",
    "    #\n",
    "    # Justificación: Documentos administrativos, oficios, informes técnicos,\n",
    "    # etc. no contienen información de búsqueda y procesarlos desperdiciaría\n",
    "    # recursos de los equipos especializados.\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    if pred[\"tipo_documento\"] == \"TD0\":\n",
    "        pred[\"ruteo\"] = \"RU0\"\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Garantizar que highlights sea siempre una lista\n",
    "    # -------------------------------------------------------------------------\n",
    "    # El modelo podría retornar None, un string, u otro tipo.\n",
    "    # Forzamos a lista vacía si no es una lista válida.\n",
    "    \n",
    "    if not isinstance(pred.get(\"highlights\"), list):\n",
    "        pred[\"highlights\"] = []\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Cálculo del score de prioridad\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Este campo NO viene del modelo; se calcula localmente basándose\n",
    "    # en las etiquetas validadas.\n",
    "    \n",
    "    pred[\"priority_score\"] = compute_priority(pred)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main-function-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Función principal: classify_document\n",
    "\n",
    "Esta es la **API pública** del clasificador. Orquesta todo el pipeline desde texto crudo hasta clasificación validada.\n",
    "\n",
    "### Pipeline completo:\n",
    "\n",
    "```\n",
    "Texto crudo del documento\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────────────────┐\n",
    "│   1. preprocess_text()      │  Limpieza y normalización\n",
    "└─────────────────────────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────────────────┐\n",
    "│   2. build_user_prompt()    │  Insertar documento en template\n",
    "└─────────────────────────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────────────────┐\n",
    "│   3. call_llm()             │  Llamada al modelo\n",
    "└─────────────────────────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────────────────┐\n",
    "│   4. parse_model_response() │  Extraer y parsear JSON\n",
    "└─────────────────────────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────────────────┐\n",
    "│   5. validate_and_fix()     │  Validar y enriquecer\n",
    "└─────────────────────────────┘\n",
    "         │\n",
    "         ▼\n",
    "Clasificación final validada\n",
    "```\n",
    "\n",
    "### Uso:\n",
    "\n",
    "```python\n",
    "resultado = classify_document(\"Mi hermano desapareció en 2003...\")\n",
    "print(resultado[\"tipo_hecho\"])      # ['TH1']\n",
    "print(resultado[\"priority_score\"])  # 0.7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab30b79-3a0f-470a-a25d-72aa34138f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 12: FUNCIÓN PRINCIPAL DE CLASIFICACIÓN\n",
    "# ==============================================================================\n",
    "# Autor: Manuel Daza Ramirez\n",
    "#\n",
    "# Propósito:\n",
    "#   Exponer una única función de alto nivel que encapsula todo el pipeline\n",
    "#   de clasificación de documentos testimoniales.\n",
    "#\n",
    "# Esta es la API pública del clasificador:\n",
    "#   - Input: Texto crudo del documento\n",
    "#   - Output: Diccionario con clasificación validada y score de prioridad\n",
    "#\n",
    "# Composición del pipeline:\n",
    "#   1. preprocess_text → Limpieza de texto\n",
    "#   2. build_user_prompt → Construcción del prompt\n",
    "#   3. call_llm → Llamada al modelo\n",
    "#   4. parse_model_response → Extracción de JSON\n",
    "#   5. validate_and_fix → Validación y enriquecimiento\n",
    "# ==============================================================================\n",
    "\n",
    "def classify_document(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Clasifica un documento testimonial usando LLM y ontología controlada.\n",
    "    \n",
    "    Esta función es el punto de entrada principal del clasificador.\n",
    "    Toma texto crudo y retorna una clasificación estructurada con:\n",
    "    - Tipo de documento (testimonial/no testimonial)\n",
    "    - Hechos victimizantes identificados\n",
    "    - Territorio geográfico\n",
    "    - Período temporal\n",
    "    - Actores involucrados\n",
    "    - Ruteo interno sugerido\n",
    "    - Fragmentos destacados (highlights)\n",
    "    - Score de prioridad calculado\n",
    "    \n",
    "    Pipeline:\n",
    "    ---------\n",
    "    text → preprocess → prompt → LLM → parse → validate → resultado\n",
    "    \n",
    "    Args:\n",
    "        text: Texto del documento testimonial (crudo, sin preprocesar)\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Clasificación con los siguientes campos:\n",
    "            - tipo_documento: str (código TD*)\n",
    "            - tipo_hecho: List[str] (códigos TH*)\n",
    "            - territorio: List[str] (nombres de departamentos)\n",
    "            - periodo: str (código PER*)\n",
    "            - actores: List[str] (códigos ACT*)\n",
    "            - ruteo: str (código RU*)\n",
    "            - highlights: List[str] (fragmentos textuales)\n",
    "            - priority_score: float (0.0 a 1.0)\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Si el modelo no retorna un JSON válido\n",
    "        openai.APIError: Si hay problemas de comunicación con la API\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> resultado = classify_document(\"\"\"\n",
    "        ...     Mi hermano Juan desapareció en 1998 en Urabá.\n",
    "        ...     Unos hombres de las autodefensas se lo llevaron.\n",
    "        ... \"\"\")\n",
    "        >>> resultado[\"tipo_documento\"]\n",
    "        'TD2'  # Testimonio de familiar\n",
    "        >>> resultado[\"tipo_hecho\"]\n",
    "        ['TH1']  # Desaparición forzada\n",
    "        >>> resultado[\"actores\"]\n",
    "        ['ACT1']  # Paramilitares\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Paso 1: Preprocesamiento\n",
    "    # Normaliza Unicode, elimina espacios múltiples, limpia headers/footers\n",
    "    # -------------------------------------------------------------------------\n",
    "    clean_text = preprocess_text(text)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Paso 2: Construcción del prompt\n",
    "    # Inserta el documento limpio en el template con ejemplos few-shot\n",
    "    # -------------------------------------------------------------------------\n",
    "    user_prompt = build_user_prompt(clean_text)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Paso 3: Llamada al LLM\n",
    "    # Envía system prompt (ontología + reglas) y user prompt (documento)\n",
    "    # -------------------------------------------------------------------------\n",
    "    raw_response = call_llm(SYSTEM_PROMPT, user_prompt)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Paso 4: Parsing de la respuesta\n",
    "    # Extrae el JSON del texto de respuesta y lo convierte a dict\n",
    "    # -------------------------------------------------------------------------\n",
    "    raw_pred = parse_model_response(raw_response)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Paso 5: Validación y enriquecimiento\n",
    "    # Corrige códigos inválidos, aplica reglas de negocio, calcula prioridad\n",
    "    # -------------------------------------------------------------------------\n",
    "    final_pred = validate_and_fix(raw_pred)\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Ejemplo de uso con testimonio sintético\n",
    "\n",
    "Esta celda demuestra el uso del clasificador con un **testimonio de prueba** que incluye los elementos típicos de un relato de víctima.\n",
    "\n",
    "### Elementos del testimonio de ejemplo:\n",
    "\n",
    "| Elemento | Valor en el texto | Clasificación esperada |\n",
    "|----------|-------------------|------------------------|\n",
    "| Tipo | Primera persona, víctima directa | TD1 |\n",
    "| Hecho 1 | \"se llevaron a mi esposo\" | TH1 (Desaparición) |\n",
    "| Hecho 2 | \"nos tocó salir\" | TH3 (Desplazamiento) |\n",
    "| Territorio | \"San Carlos, Antioquia\" | [\"Antioquia\"] |\n",
    "| Período | \"1997\" | PER2 (1985-2000) |\n",
    "| Actor | \"guerrilla\" | ACT2 |\n",
    "| Ruteo | Desaparición → prioritario | RU1 |\n",
    "\n",
    "### Resultado esperado:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"tipo_documento\": \"TD1\",\n",
    "  \"tipo_hecho\": [\"TH1\", \"TH3\"],\n",
    "  \"territorio\": [\"Antioquia\"],\n",
    "  \"periodo\": \"PER2\",\n",
    "  \"actores\": [\"ACT2\"],\n",
    "  \"ruteo\": \"RU1\",\n",
    "  \"highlights\": [\"...\"],\n",
    "  \"priority_score\": 0.7\n",
    "}\n",
    "```\n",
    "\n",
    "El `priority_score` de 0.7 resulta de: TH1 (0.4) + RU1 (0.3) = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19658b-109b-4ca5-8da5-43e91ab32327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SECCIÓN 13: EJEMPLO DE USO\n",
    "# ==============================================================================\n",
    "# Propósito:\n",
    "#   Demostrar el uso del clasificador con un testimonio de prueba.\n",
    "#   Este ejemplo es SINTÉTICO y no corresponde a un caso real.\n",
    "#\n",
    "# El testimonio de ejemplo contiene elementos típicos:\n",
    "#   - Narrador en primera persona (víctima directa o familiar)\n",
    "#   - Referencia temporal (\"1997\")\n",
    "#   - Ubicación geográfica (\"San Carlos, Antioquia\")\n",
    "#   - Actor armado (\"guerrilla\")\n",
    "#   - Hechos victimizantes (desaparición, desplazamiento)\n",
    "#\n",
    "# Resultado esperado:\n",
    "#   tipo_documento: TD1 (testimonio de víctima directa)\n",
    "#   tipo_hecho: [TH1, TH3] (desaparición forzada, desplazamiento)\n",
    "#   territorio: [Antioquia]\n",
    "#   periodo: PER2 (1985-2000)\n",
    "#   actores: [ACT2] (guerrilla)\n",
    "#   ruteo: RU1 (equipo prioritario por TH1)\n",
    "#   priority_score: 0.7 (TH1=0.4 + RU1=0.3)\n",
    "# ==============================================================================\n",
    "\n",
    "# Testimonio sintético de prueba\n",
    "# NOTA: Este texto es ficticio y se usa solo para demostración.\n",
    "# En producción se usarían documentos reales de la UBPD.\n",
    "\n",
    "testimonio = \"\"\"\n",
    "Yo, María, cuento que en 1997, en el municipio de San Carlos, Antioquia, hombres armados\n",
    "que se identificaron como de la guerrilla se llevaron a mi esposo. Desde ese día no volvimos\n",
    "a saber de él. Después de eso comenzaron las amenazas y nos tocó salir de la vereda e irnos\n",
    "para Medellín, dejando todo atrás.\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar clasificación\n",
    "resultado = classify_document(testimonio)\n",
    "\n",
    "# Mostrar resultado\n",
    "# La salida incluirá todos los campos de clasificación + priority_score\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpretation-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Interpretación del resultado\n",
    "\n",
    "El diccionario retornado contiene toda la información necesaria para:\n",
    "\n",
    "### Uso inmediato:\n",
    "- **Enrutamiento**: `ruteo` indica el equipo asignado.\n",
    "- **Priorización**: `priority_score` permite ordenar casos.\n",
    "- **Contexto rápido**: `highlights` muestra los fragmentos más relevantes.\n",
    "\n",
    "### Análisis posterior:\n",
    "- **Estadísticas territoriales**: Agregar por `territorio`.\n",
    "- **Patrones temporales**: Analizar por `periodo`.\n",
    "- **Mapeo de actores**: Cruzar `actores` con bases de datos externas.\n",
    "\n",
    "### Integración con sistemas:\n",
    "\n",
    "```python\n",
    "# Ejemplo: Insertar en base de datos\n",
    "INSERT INTO clasificaciones (\n",
    "    documento_id,\n",
    "    tipo_documento,\n",
    "    hechos,\n",
    "    territorio,\n",
    "    periodo,\n",
    "    actores,\n",
    "    ruteo,\n",
    "    priority_score\n",
    ") VALUES (\n",
    "    :doc_id,\n",
    "    :resultado['tipo_documento'],\n",
    "    :json.dumps(resultado['tipo_hecho']),\n",
    "    :json.dumps(resultado['territorio']),\n",
    "    :resultado['periodo'],\n",
    "    :json.dumps(resultado['actores']),\n",
    "    :resultado['ruteo'],\n",
    "    :resultado['priority_score']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 15. Próximos pasos y mejoras potenciales\n",
    "\n",
    "Este prototipo es funcional pero hay múltiples oportunidades de mejora:\n",
    "\n",
    "### Corto plazo:\n",
    "- [ ] Agregar manejo de errores más robusto (retry logic, timeouts)\n",
    "- [ ] Implementar logging estructurado para auditoría\n",
    "- [ ] Validar ontología contra documentos reales de la UBPD\n",
    "- [ ] Agregar más ejemplos few-shot (casos límite)\n",
    "\n",
    "### Mediano plazo:\n",
    "- [ ] Implementar batch processing para múltiples documentos\n",
    "- [ ] Agregar métricas de calidad (accuracy, F1 por categoría)\n",
    "- [ ] Crear dashboard de monitoreo\n",
    "- [ ] Integrar con base de datos PostgreSQL\n",
    "\n",
    "### Largo plazo:\n",
    "- [ ] Fine-tuning de modelo con datos etiquetados de la UBPD\n",
    "- [ ] Implementar explicabilidad (por qué se eligió cada etiqueta)\n",
    "- [ ] Agregar clasificación multi-documento (casos relacionados)\n",
    "- [ ] Integrar con sistemas de búsqueda semántica (embeddings + vector DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de37c6",
   "metadata": {},
   "source": [
    "---\n",
    "**Notebook preparado por:** Manuel Daza Ramirez  \n",
    "Rol: AI Engineer (prototipo de clasificación de documentos testimoniales)  \n",
    "Versión: 2025-02  \n",
    "\n",
    "---\n",
    "\n",
    "### Licencia y uso\n",
    "\n",
    "Este notebook es un **prototipo de demostración** desarrollado para mostrar capacidades de clasificación automática de documentos testimoniales usando LLMs.\n",
    "\n",
    "**Contacto:**\n",
    "- LinkedIn: [linkedin.com/in/manueldazaramirez](https://linkedin.com/in/manueldazaramirez)\n",
    "- Email: manuel.dazaramirez@gmail.com\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
