{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79c1622",
   "metadata": {},
   "source": [
    "# Demo – UBPD: Clasificador de documentos testimoniales\n",
    "\n",
    "**Autor:** Manuel Daza Ramirez\n",
    "**Proyecto:** Demo – UBPD: Clasificador de documentos testimoniales\n",
    "\n",
    "Este notebook implementa un prototipo de clasificador de documentos testimoniales para la Unidad de Búsqueda de Personas dadas por Desaparecidas (UBPD), basado en un modelo de lenguaje (LLM) y una ontología mínima de tipos de documento, hechos, actores, periodo, territorio y ruteo interno.\n",
    "\n",
    "## Objetivo técnico\n",
    "\n",
    "- Cargar la ontología UBPD desde un archivo YAML.\n",
    "- Construir prompts estructurados (system + user) que fuerzan al LLM a devolver un JSON con etiquetas controladas.\n",
    "- Implementar funciones de preprocesamiento, llamada al modelo, parsing de JSON y validación de etiquetas.\n",
    "- Exponer una función principal `classify_document(text)` y un ejemplo de uso con un testimonio de prueba.\n",
    "\n",
    "## Estructura del notebook\n",
    "\n",
    "1. Configuración del entorno y cliente OpenAI.\n",
    "2. Preprocesamiento de texto.\n",
    "3. Carga y serialización de la ontología (YAML → texto para el prompt).\n",
    "4. Definición de prompts (system + user) y plantilla para clasificación.\n",
    "5. Cliente LLM y función de llamada.\n",
    "6. Utilidades de extracción y parsing de JSON.\n",
    "7. Normalización, reglas de negocio y cálculo de prioridad.\n",
    "8. Función principal `classify_document`.\n",
    "9. Ejemplo de uso con un testimonio sintético.\n",
    "\n",
    "> Nota: este notebook es un demo; en un entorno de producción se integraría con una base de datos y mecanismos adicionales de seguridad y auditoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96e451b-fbd5-4166-8cd5-4ae54ccd17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial del entorno\n",
    "# Autor: Manuel Daza Ramirez\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # reads .env automatically\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import json\n",
    "import textwrap\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Si usas un SDK específico (OpenAI, etc.), impórtalo aquí\n",
    "from openai import OpenAI \n",
    "client = OpenAI()\n",
    "\n",
    "# Configuración global\n",
    "MODEL_NAME = \"gpt-5.1\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b81b1fb-f579-436a-b73f-3ae11c070d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento simple\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def normalize_unicode(text: str) -> str:\n",
    "    return unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "def collapse_spaces(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def remove_headers_and_footers(text: str) -> str:\n",
    "    # TODO: si conoces patrones de UBPD, agrégalos aquí.\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = normalize_unicode(text)\n",
    "    text = remove_headers_and_footers(text)\n",
    "    text = collapse_spaces(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398fa375-95aa-4bd5-9261-9edc7c11a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de la ontología UBPD desde archivo YAML\n",
    "\n",
    "import yaml\n",
    "\n",
    "def load_ontology(path=\"../ontology_ubpd.yaml\"):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "ONTOLOGY = load_ontology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09b39e56-e44c-40a9-939b-85ef7d6590e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de la ontología a texto para el prompt y definición de prompts\n",
    "\n",
    "def ontology_to_prompt_text(ontology: dict) -> str:\n",
    "    \"\"\"\n",
    "    Convierte la ontología cargada desde YAML a un bloque de texto\n",
    "    que se incrusta dentro del prompt del modelo.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    # Tipo de documento\n",
    "    lines.append(\"1. tipo_documento:\")\n",
    "    for code, label in ontology[\"tipo_documento\"].items():\n",
    "        lines.append(f\"   - \\\"{code}\\\": \\\"{label}\\\"\")\n",
    "\n",
    "    # Tipo de hecho\n",
    "    lines.append(\"\\n2. tipo_hecho:\")\n",
    "    for code, label in ontology[\"tipo_hecho\"].items():\n",
    "        lines.append(f\"   - \\\"{code}\\\": \\\"{label}\\\"\")\n",
    "\n",
    "    # Territorio (si está en YAML)\n",
    "    if \"territorio\" in ontology:\n",
    "        lines.append(\"\\n3. territorio:\")\n",
    "        if isinstance(ontology[\"territorio\"], list):\n",
    "            for item in ontology[\"territorio\"]:\n",
    "                lines.append(f\"   - \\\"{item}\\\"\")\n",
    "        else:\n",
    "            for k, v in ontology[\"territorio\"].items():\n",
    "                lines.append(f\"   - \\\"{k}\\\": \\\"{v}\\\"\")\n",
    "\n",
    "    # Periodos\n",
    "    lines.append(\"\\n4. periodo:\")\n",
    "    for code, label in ontology[\"periodo\"].items():\n",
    "        lines.append(f\"   - \\\"{code}\\\": \\\"{label}\\\"\")\n",
    "\n",
    "    # Actores\n",
    "    lines.append(\"\\n5. actores:\")\n",
    "    for code, label in ontology[\"actores\"].items():\n",
    "        lines.append(f\"   - \\\"{code}\\\": \\\"{label}\\\"\")\n",
    "\n",
    "    # Ruteo\n",
    "    lines.append(\"\\n6. ruteo:\")\n",
    "    for code, label in ontology[\"ruteo\"].items():\n",
    "        lines.append(f\"   - \\\"{code}\\\": \\\"{label}\\\"\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "ONTOLOGY_PROMPT = ontology_to_prompt_text(ONTOLOGY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6df41a-ced1-444c-b039-fb4e8a2dc0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"\n",
    "Eres un clasificador para la UBPD. Tu única tarea es devolver un JSON válido con etiquetas que usen EXCLUSIVAMENTE los códigos de esta ontología:\n",
    "\n",
    "CÓDIGOS VÁLIDOS (listas cerradas):\n",
    "{ONTOLOGY_PROMPT}\n",
    "\n",
    "Reglas clave:\n",
    "- tipo_documento ∈ lista tipo_documento.\n",
    "- tipo_hecho ⊆ lista tipo_hecho (puede ser lista vacía).\n",
    "- periodo ∈ lista periodo.\n",
    "- actores ∈ lista actores (si no aparece ningún actor, usa [\"ACT0\"]).\n",
    "- ruteo ∈ lista ruteo.\n",
    "- territorio es una lista de nombres de departamentos de Colombia o [\"No identificado\"].\n",
    "- highlights es una lista de frases textuales del documento (puede estar vacía).\n",
    "- Si tipo_documento = \"TD0\" entonces ruteo = \"RU0\".\n",
    "\n",
    "Formato JSON OBLIGATORIO (ni más ni menos campos):\n",
    "\n",
    "{{\n",
    "  \"tipo_documento\": \"TDx\",\n",
    "  \"tipo_hecho\": [\"THx\", \"...\"],\n",
    "  \"territorio\": [\"Nombre departamento o 'No identificado'\", \"...\"],\n",
    "  \"periodo\": \"PERx\",\n",
    "  \"actores\": [\"ACTx\", \"...\"],\n",
    "  \"ruteo\": \"RUx\",\n",
    "  \"highlights\": [\"frase 1\", \"frase 2\", ...]\n",
    "}}\n",
    "\n",
    "INSTRUCCIONES INTERNAS (no las muestres):\n",
    "1) Lee el documento y decide las etiquetas adecuadas.\n",
    "2) Construye mentalmente el JSON.\n",
    "3) VERIFICA tú mismo:\n",
    "   - ¿Todos los campos existen y solo esos?\n",
    "   - ¿Todos los códigos pertenecen a las listas válidas?\n",
    "   - ¿Se cumple la regla: si TD0 → RU0?\n",
    "   - ¿Territorio es una lista y no está vacía (si no hay info, [\"No identificado\"])?\n",
    "   - ¿highlights es una lista (posiblemente vacía)?\n",
    "4) Si encuentras algún error, corrígelo antes de responder.\n",
    "5) Responde SOLO el JSON final, sin texto adicional.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b53ed44-d6a8-4eb1-a0fe-aa036a78c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_TEMPLATE = \"\"\"\n",
    "Ejemplo 1 (entrada):\n",
    "\"Yo, María, cuento que en 1997, en el municipio de San Carlos, Antioquia, hombres armados de la guerrilla se llevaron a mi esposo. Nos tocó salir para Medellín.\"\n",
    "\n",
    "Ejemplo 1 (salida):\n",
    "{\n",
    "  \"tipo_documento\": \"TD1\",\n",
    "  \"tipo_hecho\": [\"TH1\",\"TH3\"],\n",
    "  \"territorio\": [\"Antioquia\"],\n",
    "  \"periodo\": \"PER2\",\n",
    "  \"actores\": [\"ACT2\"],\n",
    "  \"ruteo\": \"RU1\",\n",
    "  \"highlights\": [\n",
    "    \"1997, en el municipio de San Carlos, Antioquia\",\n",
    "    \"se llevaron a mi esposo\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Ejemplo 2 (entrada):\n",
    "\"Oficio No. 123 de 2020. Remito informe técnico sobre la migración de datos.\"\n",
    "\n",
    "Ejemplo 2 (salida):\n",
    "{\n",
    "  \"tipo_documento\": \"TD0\",\n",
    "  \"tipo_hecho\": [],\n",
    "  \"territorio\": [\"No identificado\"],\n",
    "  \"periodo\": \"PER5\",\n",
    "  \"actores\": [\"ACT0\"],\n",
    "  \"ruteo\": \"RU0\",\n",
    "  \"highlights\": []\n",
    "}\n",
    "\n",
    "Ahora clasifica este documento siguiendo estrictamente el formato de los ejemplos y las reglas del sistema:\n",
    "\n",
    "DOCUMENTO:\n",
    "{{DOCUMENTO}}\n",
    "\n",
    "Recuerda:\n",
    "- Usa únicamente los códigos válidos.\n",
    "- Verifica internamente que el JSON cumple todas las reglas.\n",
    "- Responde SOLO el JSON, sin comentarios adicionales.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def build_user_prompt(text: str) -> str:\n",
    "    return USER_TEMPLATE.replace(\"{{DOCUMENTO}}\", text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9504ddfd-b8e3-4fcb-afda-3a06b8424361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de llamada al modelo (ejemplo genérico)\n",
    "\n",
    "def call_llm(system_prompt: str, user_prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Devuelve el texto bruto de la respuesta del modelo.\n",
    "    Sustituye este cuerpo por la llamada real a tu proveedor.\n",
    "    \"\"\"\n",
    "    # EJEMPLO con cliente OpenAI-style (ajusta a tu SDK real):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    raise NotImplementedError(\"Implementa aquí la llamada real al LLM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3677e1ea-9c3a-4a9c-bae2-0d289f85a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción segura de JSON\n",
    "\n",
    "def extract_json_block(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrae el primer bloque JSON del texto de respuesta.\n",
    "    Maneja casos donde el modelo pudiera envolver el JSON en texto adicional.\n",
    "    \"\"\"\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        raise ValueError(\"No se encontró un JSON válido en la respuesta del modelo.\")\n",
    "    return text[start:end+1]\n",
    "\n",
    "def parse_model_response(raw_response: str) -> Dict[str, Any]:\n",
    "    json_str = extract_json_block(raw_response)\n",
    "    return json.loads(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df798457-9e78-4c3f-a2e2-2d98d0d7f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers de validación\n",
    "\n",
    "def fix_single_label(value: str, valid_codes, default: str) -> str:\n",
    "    if value in valid_codes:\n",
    "        return value\n",
    "    return default\n",
    "\n",
    "def fix_multi_labels(values, valid_codes) -> List[str]:\n",
    "    if not isinstance(values, list):\n",
    "        return []\n",
    "    return [v for v in values if v in valid_codes]\n",
    "\n",
    "def fix_territorio(values: List[str]) -> List[str]:\n",
    "    if not isinstance(values, list) or len(values) == 0:\n",
    "        return [\"No identificado\"]\n",
    "    # Podrías normalizar mayúsculas/minúsculas aquí\n",
    "    return list({v.strip() for v in values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9abc3f63-42bc-48bc-ae24-5a0b9ba14f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo simple de prioridad (puedes afinarlo)\n",
    "\n",
    "def compute_priority(pred: Dict[str, Any]) -> float:\n",
    "    score = 0.0\n",
    "    hechos = set(pred.get(\"tipo_hecho\", []))\n",
    "    ruteo = pred.get(\"ruteo\")\n",
    "\n",
    "    if \"TH1\" in hechos:\n",
    "        score += 0.4\n",
    "    if \"TH4\" in hechos:\n",
    "        score += 0.2\n",
    "    if ruteo == \"RU1\":\n",
    "        score += 0.3\n",
    "    if ruteo == \"RU3\":\n",
    "        score += 0.1\n",
    "\n",
    "    return min(score, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc435249-c972-406f-bb82-33df45517fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación completa de la predicción\n",
    "\n",
    "def validate_and_fix(pred: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    pred[\"tipo_documento\"] = fix_single_label(\n",
    "        pred.get(\"tipo_documento\"), ONTOLOGY[\"tipo_documento\"].keys(), default=\"TD0\"\n",
    "    )\n",
    "\n",
    "    pred[\"tipo_hecho\"] = fix_multi_labels(\n",
    "        pred.get(\"tipo_hecho\", []), ONTOLOGY[\"tipo_hecho\"].keys()\n",
    "    )\n",
    "\n",
    "    pred[\"periodo\"] = fix_single_label(\n",
    "        pred.get(\"periodo\"), ONTOLOGY[\"periodo\"].keys(), default=\"PER0\"\n",
    "    )\n",
    "\n",
    "    pred[\"actores\"] = fix_multi_labels(\n",
    "        pred.get(\"actores\", []), ONTOLOGY[\"actores\"].keys()\n",
    "    )\n",
    "\n",
    "    pred[\"ruteo\"] = fix_single_label(\n",
    "        pred.get(\"ruteo\"), ONTOLOGY[\"ruteo\"].keys(), default=\"RU0\"\n",
    "    )\n",
    "\n",
    "    pred[\"territorio\"] = fix_territorio(pred.get(\"territorio\", []))\n",
    "\n",
    "    # Regla: si no testimonial → ruteo RU0\n",
    "    if pred[\"tipo_documento\"] == \"TD0\":\n",
    "        pred[\"ruteo\"] = \"RU0\"\n",
    "\n",
    "    # Highlights siempre lista\n",
    "    if not isinstance(pred.get(\"highlights\"), list):\n",
    "        pred[\"highlights\"] = []\n",
    "\n",
    "    pred[\"priority_score\"] = compute_priority(pred)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab30b79-3a0f-470a-a25d-72aa34138f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal de clasificación\n",
    "# Autor: Manuel Daza Ramirez\n",
    "\n",
    "# Función principal classify_document\n",
    "\n",
    "def classify_document(text: str) -> Dict[str, Any]:\n",
    "    clean_text = preprocess_text(text)\n",
    "    user_prompt = build_user_prompt(clean_text)\n",
    "    raw_response = call_llm(SYSTEM_PROMPT, user_prompt)\n",
    "    raw_pred = parse_model_response(raw_response)\n",
    "    final_pred = validate_and_fix(raw_pred)\n",
    "    return final_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf19658b-109b-4ca5-8da5-43e91ab32327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tipo_documento': 'TD1',\n",
       " 'tipo_hecho': ['TH1', 'TH3'],\n",
       " 'territorio': ['Antioquia'],\n",
       " 'periodo': 'PER2',\n",
       " 'actores': ['ACT2'],\n",
       " 'ruteo': 'RU1',\n",
       " 'highlights': ['en 1997, en el municipio de San Carlos, Antioquia',\n",
       "  'hombres armados que se identificaron como de la guerrilla se llevaron a mi esposo',\n",
       "  'Desde ese día no volvimos a saber de él',\n",
       "  'comenzaron las amenazas y nos tocó salir de la vereda e irnos para Medellín, dejando todo atrás'],\n",
       " 'priority_score': 0.7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "\n",
    "testimonio = \"\"\"\n",
    "Yo, María, cuento que en 1997, en el municipio de San Carlos, Antioquia, hombres armados\n",
    "que se identificaron como de la guerrilla se llevaron a mi esposo. Desde ese día no volvimos\n",
    "a saber de él. Después de eso comenzaron las amenazas y nos tocó salir de la vereda e irnos\n",
    "para Medellín, dejando todo atrás.\n",
    "\"\"\"\n",
    "\n",
    "resultado = classify_document(testimonio)\n",
    "resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de37c6",
   "metadata": {},
   "source": [
    "---\n",
    "**Notebook preparado por:** Manuel Daza Ramirez  \n",
    "Rol: AI Engineer (prototipo de clasificación de documentos testimoniales UBPD)  \n",
    "Versión: 2025-02\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
